{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets==3.6.0\n",
        "!pip install transformers[sentencepiece] accelerate evaluate rouge_score conllu -q\n",
        "\n",
        "from pathlib import Path\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import login, ModelCard, ModelCardData\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    pipeline,\n",
        ")\n",
        "import os, re, textwrap, evaluate\n",
        "import numpy as np\n",
        "import ast"
      ],
      "metadata": {
        "id": "RqQPdWxo-Obv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "398d53e9-1bb2-4040-8139-62c7ce157d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==3.6.0\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.6.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: datasets\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed datasets-3.6.0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"universal_dependencies\", \"tr_boun\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "UgkBHbtl-QOv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397,
          "referenced_widgets": [
            "c686b62592fc46f28fb79ca5851c63b7",
            "f8ef4f00c3934e7b85c19c3c1cc6eddb",
            "297634bf85654c0ba5865492366cfd28",
            "d369a4deb3634711ab92d5f7b96f0685",
            "132d8a91ca494b489e60a1a381d8a64f",
            "f44b8dd6e4ab49ecabc7bf85419c1385",
            "ed6515208a6a4fd3b9a24c766458014a",
            "fa34deda7fec44338938212c52a1e43c",
            "1aa420de4f9640bcb4dbf48cef28f7d6",
            "181e551904454e2fb82b525b3a50d01e",
            "d075137d967a459cbff2dfc48f19f89f",
            "279d272fa050477e8bf6b5afdb3acd3e",
            "fc7264e7bb11472e89ebd716c1a0b11d",
            "fed742db81404d15ae166fb593fdd744",
            "5428ae4a5f2d48be999b2f0fe61796a1",
            "97272f59258f4c2d8b665133a2a71cde",
            "eec65accf7724cbea31feb81a4d23c59",
            "fb92eac2245948789b42455032e41995",
            "f11ac40765474f269eea3148d386b526",
            "d558484cfbbc421db85850602a5440d6",
            "94ed14aa78144412b66b7f6ba7db53bf",
            "31800de96474409496bac9aa0ffce093",
            "f5c70a6dd4a24bc29621c3e7b4e8347a",
            "899bc7675a754824b3ccf2ebd1a09be8",
            "fd9818ece7f7423981dc8266babc0a69",
            "8cbb93378f9540a6a9874d34c5cdba82",
            "43d41be13c35486fb0b4416d0278bec5",
            "b68cac92121a414cbc41dc117a2bf5b9",
            "57a83830ad5d487d8f7e9a43afbf906d",
            "307e0e98dd20403d9b91f271a6b3fd1d",
            "5b4b87625a6a45429128b1791ffcede5",
            "b8a55c9a1fdd414db3b2d9c78c9f3327",
            "49d533a31e4e49debe27695c678336f2",
            "2c2dafa1b81c4dfcb8c7966fd39a757a",
            "da694261dd544e18aa9a668a92f9a95f",
            "3e3310bf5e844b78a134029170fdaf0c",
            "2ca6e7db95e0439bb6a7227f37763675",
            "ab2a8924979344c5a6d5208a93dab091",
            "aac9f73d685941628205041deffc2db8",
            "74ecd9db87974501b2fec3197d286d5d",
            "25443779192441a594b97b2f81724bf0",
            "9dc9dcf78014451d9da987b85c49acbd",
            "5f073278f8ff470c805e276cf5a7ed80",
            "71be40df72c24856aea357e49d7345f7",
            "ab5bd6d7ab4d442f8e29f704e3e4ac2a",
            "fcbfb6997c91446394484124b13a65f3",
            "ac1ad42fcc8d45a89482940740c4db6d",
            "51902a6988e5490fa55da0631dc344d5",
            "161341be7796464eb39bfa6f6496e373",
            "35cd25a6fbbf47eb841fd838ca21b377",
            "52ce92ddc7ad457a805a265fa0adcc69",
            "87f32d5cdd994bd0b10f30b2d4079b82",
            "d9ac2cfcb5c24bcb8a3e1a26c0094c57",
            "d5db4002b78f416e81a9ebee56980877",
            "66dfec56c7714dfe8b1df0ae045cd408",
            "425797f0d5c24799bc321f6a0d094425",
            "46328162b92a4a37823ed20dbb2a758f",
            "c1c711bd901f413d8849b7405f9a039f",
            "146a7b1a99df43d181e5e4993de81744",
            "a277b6b0fed0462aa9c30e4615223a3e",
            "611426ea49b94cef80138427ae8b75b1",
            "7af4a6c6991847fa9457c13a3b66b080",
            "0be7c3b10eb446d4ab55f1c64b50aa5e",
            "490da8d9d7934452905f3823ede66b61",
            "5ef965fb32f441fc9a13fa5f66f7aaf0",
            "f689e74247e24a5f834fcd0cf6825656",
            "bdd58fc7a06f49a5b5f84a456c666e59",
            "86706f21eb86411f91d5f4c88c03dfc3",
            "4fc2df21d2814fde9f4b222262d23abd",
            "c63acb03ebff428abee55fe28741cafc",
            "fa8d6956ab074a1eabfa2f520954c765",
            "a4910879e901461d880ee080272eb014",
            "fe562c7cc8904d35bb6081a3b85f5df4",
            "dbe1b3e1ea404bea879fb8db93d658a7",
            "92a77031020a4c3b989bffc05ef7baa6",
            "be7c4d1ae6584457acf3b8d77ee75d66",
            "bfa447ebb3874d38bf71d0f3fe2b941a",
            "0b52492fd9924724a6f977b61cd1ffc2",
            "923a031f9ea44583b945b0625b22ab4f",
            "7310c49f2ef84c86bfc1f156cce5ab6a",
            "57e80b22827c4af6982efc208103d534",
            "e4f952e312a04c03a5a8e3a2d52fb766",
            "dd6e48f4d84641958faa0887c4928a25",
            "ead9f2382a5a407d9a442339487d790a",
            "c992fcae25bf4736b3ff66a375020669",
            "14dbe251e4db4ff195a371a5813c737a",
            "1738189e02f048a9b0d424bc8d32a96f",
            "82357b7a21ad49f4ba395f50a06b8b91"
          ]
        },
        "outputId": "de83e004-d3fc-4df7-a374-693aded45e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c686b62592fc46f28fb79ca5851c63b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "universal_dependencies.py: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "279d272fa050477e8bf6b5afdb3acd3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/7.82M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5c70a6dd4a24bc29621c3e7b4e8347a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/962k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c2dafa1b81c4dfcb8c7966fd39a757a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/963k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab5bd6d7ab4d442f8e29f704e3e4ac2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/7803 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "425797f0d5c24799bc321f6a0d094425"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/979 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdd58fc7a06f49a5b5f84a456c666e59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/979 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b52492fd9924724a6f977b61cd1ffc2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "Janu-PaWbmuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f704bda8-e4ab-4d44-d5be-25a5a6ab9e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
            "        num_rows: 7803\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
            "        num_rows: 979\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
            "        num_rows: 979\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = len(dataset['train'])\n",
        "validation_size = len(dataset['validation'])\n",
        "test_size = len(dataset['test'])\n",
        "\n",
        "print(f\"Eğitim veriseti boyutu: {train_size} cümle\")\n",
        "print(f\"Doğrulama veriseti boyutu: {validation_size} cümle\")\n",
        "print(f\"Test veriseti boyutu: {test_size} cümle\")"
      ],
      "metadata": {
        "id": "pLoPsWavbsYA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d740b9e-c6ad-4ae5-a1ec-4cabd7c625f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eğitim veriseti boyutu: 7803 cümle\n",
            "Doğrulama veriseti boyutu: 979 cümle\n",
            "Test veriseti boyutu: 979 cümle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_names = dataset['train'].features['upos'].feature.names\n",
        "\n",
        "print(\"Kelime Türü Numaraları ve Karşılıkları:\")\n",
        "for i, name in enumerate(pos_names):\n",
        "    print(f\"Sayı: {i:<5} -> Metin: {name}\")"
      ],
      "metadata": {
        "id": "yTG2cUejCt9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15a7b07-0fa8-483b-a70a-73e65a59921d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kelime Türü Numaraları ve Karşılıkları:\n",
            "Sayı: 0     -> Metin: NOUN\n",
            "Sayı: 1     -> Metin: PUNCT\n",
            "Sayı: 2     -> Metin: ADP\n",
            "Sayı: 3     -> Metin: NUM\n",
            "Sayı: 4     -> Metin: SYM\n",
            "Sayı: 5     -> Metin: SCONJ\n",
            "Sayı: 6     -> Metin: ADJ\n",
            "Sayı: 7     -> Metin: PART\n",
            "Sayı: 8     -> Metin: DET\n",
            "Sayı: 9     -> Metin: CCONJ\n",
            "Sayı: 10    -> Metin: PROPN\n",
            "Sayı: 11    -> Metin: PRON\n",
            "Sayı: 12    -> Metin: X\n",
            "Sayı: 13    -> Metin: _\n",
            "Sayı: 14    -> Metin: ADV\n",
            "Sayı: 15    -> Metin: INTJ\n",
            "Sayı: 16    -> Metin: VERB\n",
            "Sayı: 17    -> Metin: AUX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ilk_ornek = dataset['train'][333]\n",
        "print(\"--- CÜMLENİN ORİJİNALİ ---\")\n",
        "print(ilk_ornek['text'])\n",
        "print(\"\\n--- CÜMLENİN PARÇALARI ---\")\n",
        "\n",
        "for i in range(len(ilk_ornek['tokens'])):\n",
        "    kelime = ilk_ornek['tokens'][i]\n",
        "    kok = ilk_ornek['lemmas'][i]\n",
        "    tur_id = ilk_ornek['upos'][i]\n",
        "    tur_metni = pos_names[tur_id]\n",
        "    ekler = ilk_ornek['feats'][i]\n",
        "\n",
        "    print(f\"Kelime: {kelime:<15} | Kök: {kok:<15} | Tür: {tur_metni:<10} | Ek Bilgileri: {ekler}\")"
      ],
      "metadata": {
        "id": "LZu5IUQoBdkr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c37a372-7ee9-4c14-a21c-e9aecd8ec1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- CÜMLENİN ORİJİNALİ ---\n",
            "Ben titriyor, için için ağlıyor ve hiçbir şey yapamamanın ezikliğini yaşıyordum.\n",
            "\n",
            "--- CÜMLENİN PARÇALARI ---\n",
            "Kelime: Ben             | Kök: ben             | Tür: PRON       | Ek Bilgileri: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1'}\n",
            "Kelime: titriyor        | Kök: titre           | Tür: VERB       | Ek Bilgileri: {'Aspect': 'Prog', 'Number': 'Sing', 'Person': '3', 'Polarity': 'Pos', 'Tense': 'Pres'}\n",
            "Kelime: ,               | Kök: ,               | Tür: PUNCT      | Ek Bilgileri: None\n",
            "Kelime: için            | Kök: için            | Tür: ADV        | Ek Bilgileri: None\n",
            "Kelime: için            | Kök: için            | Tür: ADP        | Ek Bilgileri: None\n",
            "Kelime: ağlıyor         | Kök: ağla            | Tür: VERB       | Ek Bilgileri: {'Aspect': 'Prog', 'Number': 'Sing', 'Person': '3', 'Polarity': 'Pos', 'Tense': 'Pres'}\n",
            "Kelime: ve              | Kök: ve              | Tür: CCONJ      | Ek Bilgileri: None\n",
            "Kelime: hiçbir          | Kök: hiçbir          | Tür: DET        | Ek Bilgileri: None\n",
            "Kelime: şey             | Kök: şey             | Tür: NOUN       | Ek Bilgileri: {'Case': 'Nom', 'Number': 'Sing', 'Person': '3'}\n",
            "Kelime: yapamamanın     | Kök: yap             | Tür: VERB       | Ek Bilgileri: {'Case': 'Gen', 'Number': 'Sing', 'Person': '3', 'Polarity': 'Neg'}\n",
            "Kelime: ezikliğini      | Kök: ezik            | Tür: NOUN       | Ek Bilgileri: {'Case': 'Acc', 'Number': 'Sing', 'Number[psor]': 'Sing', 'Person': '3', 'Person[psor]': '3'}\n",
            "Kelime: yaşıyordum      | Kök: yaşa            | Tür: VERB       | Ek Bilgileri: {'Aspect': 'Prog', 'Evident': 'Fh', 'Number': 'Sing', 'Person': '1', 'Polarity': 'Pos', 'Tense': 'Past'}\n",
            "Kelime: .               | Kök: .               | Tür: PUNCT      | Ek Bilgileri: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bigscience/mt0-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "HbDUaCTHKT4X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "888c427173284018904b46854771cad6",
            "8e75091b822d41e2bca3d656e6bb7c43",
            "40060c3f78b04ba781141e32f0db8765",
            "2c2ea2f11882420dbf8597e3754c203a",
            "0e725a8f85aa40e9bbe7def91feb35a0",
            "16850bd5e2744ec2829263ba9ec1fdf9",
            "969cf2fb5eea47199e0386cbfe84e344",
            "fa86e5eff5cf465783e60a3e7cbab719",
            "d428f0073dff4d0ebe2dcbb1d76c9992",
            "f3d9d02f4b864f5dbaeb4142527ead88",
            "3f0519a8cb25415793a046726c631438",
            "ccc4f71a25cb47a89ea53e9d94fc8655",
            "573eef84d4b445d1a84a608498501a50",
            "b5d9f299d0934a6eb97c0242659aea7d",
            "e93503ea108c4844af18f65ff06b399d",
            "c9117ad6bd384e17af62eb0da69d1022",
            "61715d19591344a3a1df7ea4b1b573e8",
            "51f4c97c6e2a42b19fdf6cefad6fee51",
            "6f9c4466801043a58c175b2de7db9021",
            "620e1d7fdb084715ba9736238ffcac54",
            "1fc6acc6e3c44ff0b0a9d40467daa817",
            "facb0b97698d4ebabb35c4e3d3da93a7",
            "21fbc75ef5564dcebcd699301c65f0b0",
            "417bef871d0a4ba890d20dfc8f3755b8",
            "e3bccf96b6b447d8981116ecf2ad75f8",
            "dd9fe01d14fc434b8615668b98c5d660",
            "338e1cd9d53142688778a784944654cd",
            "97c2339a606142eda995ece92b45518e",
            "75856bf7ff15443da74e1ba8cdd9a8c4",
            "2e6fc04ff8594fa8a243505bc203ed8a",
            "cccdfe9a370d4964bd2a0c919df65466",
            "17636d461a0a404a96e76b591c1527b8",
            "997a513eb2a3468189c0f74ac4886553",
            "2a707f0af4644bff9bb9f90c65f389b8",
            "dfeb102722bc4c51af638b14588bcb0c",
            "0463cb0c14544fd689420acac17e2750",
            "d6789aa5ccb14442b7eb24631504f0e4",
            "390eb043e33341be9d24c4a5b1f8fb17",
            "a07fbe42df724b039aff2216d5f039b6",
            "55f901daf81c4257b3c068b9002a85ae",
            "d1088cbbf0b9458a990613be9b8680db",
            "901df4908364469c8555abfaf18c7e5f",
            "1f2e3c4b5bda4d55b0a5cfd74217f41a",
            "df1cfa134afb4db6b16b69cd8b723dbb",
            "26a3eebc564340efad18acc9ae653029",
            "4405924edabc44ebab921dcb0cbaa5bf",
            "5b2538e489314ab3b43e383352763f96",
            "f9c68098c06e4c468e00f3fd5b9da263",
            "a9c99b4ee0674c6aaf93544da4159f1b",
            "99ac810afd4f4c98a50a211ccccd588f",
            "ba4bf2b5003947349783d1623b7f2d8b",
            "1e2f05488d124571a2145ecb5f51a438",
            "67fff10351c54b6698af09fd4f47971f",
            "aa588357a3dd47f6a4265ce51d143aca",
            "a4b1881dce7c4135806cca51506464e3",
            "891f99ee44bf4e10a9c8a35ecb3a0801",
            "f2e307ed789f4453aaf9d5678dfe06e9",
            "0339a00089c3457fb5b791d1bc837506",
            "68cb81a823cb40c5861c6b66025d09e4",
            "9f04a3d142794742a687755d55885f30",
            "e748eb253933426e9dfc23d73aad2e0d",
            "c7d7c5ac39374bc4bd567980208ca62a",
            "d7ef7f3a6a6c4fb19682a96db99fddba",
            "f8b0092a977942e4b7377285ae99eb11",
            "cab6338f62874444a56d82714ac564b2",
            "c7ca1e708c364a939661710e30895bbd"
          ]
        },
        "outputId": "44ea70fb-5ff8-47ec-cb37-7074bb944453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/430 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "888c427173284018904b46854771cad6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccc4f71a25cb47a89ea53e9d94fc8655"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21fbc75ef5564dcebcd699301c65f0b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a707f0af4644bff9bb9f90c65f389b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/773 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26a3eebc564340efad18acc9ae653029"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "891f99ee44bf4e10a9c8a35ecb3a0801"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UD_TO_TR_POS_MAP = {\n",
        "    \"NOUN\": \"isim\", \"VERB\": \"fiil\", \"ADJ\": \"sıfat\", \"ADV\": \"zarf\",\n",
        "    \"PRON\": \"zamir\", \"PROPN\": \"özel isim\", \"NUM\": \"sayı\", \"ADP\": \"edat\",\n",
        "    \"CCONJ\": \"bağlaç\", \"AUX\": \"yardımcı fiil\", \"DET\": \"belirteç\",\n",
        "    \"PART\": \"partikül\", \"SCONJ\": \"alt-bağlaç\", \"INTJ\": \"ünlem\",\n",
        "}\n",
        "\n",
        "\n",
        "UD_FEATURE_TO_TR_MAP = {\n",
        "    \"Case=Acc\": \"-i(belirtme)\", \"Case=Dat\": \"-e(yönelme)\", \"Case=Loc\": \"-de(bulunma)\",\n",
        "    \"Case=Abl\": \"-den(ayrılma)\", \"Case=Gen\": \"-in(tamlayan)\", \"Case=Ins\": \"-le(vasıta)\",\n",
        "    \"Case=Nom\": \"(yalın)\",\n",
        "    \"Number=Sing\": \"(tekil)\", \"Number=Plur\": \"-ler(çoğul)\",\n",
        "    \"Number[psor]=Sing\": \"(iyelik tekil)\", \"Number[psor]=Plur\": \"(iyelik çoğul)\",\n",
        "    \"Person=1\": \"(1.kişi)\", \"Person=2\": \"(2.kişi)\", \"Person=3\": \"(3.kişi)\",\n",
        "    \"Person[psor]=1\": \"(1.kişi iyelik)\", \"Person[psor]=2\": \"(2.kişi iyelik)\", \"Person[psor]=3\": \"(3.kişi iyelik)\",\n",
        "    \"Tense=Pres\": \"-(i)yor(şimdiki z.)\", \"Tense=Past\": \"-di(geçmiş z.)\", \"Tense=Fut\": \"-ecek(gelecek z.)\",\n",
        "    \"Tense=Pqp\": \"-mişti(öğ. geç. hik.)\",\n",
        "    \"Aspect=Perf\": \"(belirli geçmiş)\", \"Aspect=Prog\": \"-mekte(sürmekte)\",\n",
        "    \"Aspect=Hab\": \"-er(geniş z.)\",\n",
        "    \"Polarity=Neg\": \"-me(olumsuzluk)\", \"Polarity=Pos\": \"(olumlu)\",\n",
        "    \"VerbForm=Vnoun\": \"-mek(isim-fiil)\", \"VerbForm=Part\": \"-en(sıfat-fiil)\", \"VerbForm=Conv\": \"-erek(zarf-fiil)\",\n",
        "    \"Mood=Imp\": \"(emir)\", \"Mood=Opt\": \"-e(istek)\", \"Mood=Cnd\": \"-se(şart)\",\n",
        "    \"Mood=Pot\": \"-ebil(yeterlilik)\", \"Mood=Gen\": \"(genel kip)\",\n",
        "    \"Voice=Pass\": \"-il(edilgen)\", \"Voice=Rcp\": \"-iş(işteş)\", \"Voice=Cau\": \"-dir(ettirgen)\",\n",
        "    \"PronType=Prs\": \"(kişi zamiri)\"\n",
        "}\n",
        "\n",
        "POS_NAMES = dataset['train'].features['upos'].feature.names\n",
        "\n",
        "def prepare_data_for_training(dataset_batch):\n",
        "    inputs, targets = [], []\n",
        "    num_rows = len(dataset_batch[list(dataset_batch.keys())[0]])\n",
        "\n",
        "    for i in range(num_rows):\n",
        "        ornek = {key: dataset_batch[key][i] for key in dataset_batch}\n",
        "        inputs.append(ornek['text'])\n",
        "\n",
        "        analiz_parcalari = []\n",
        "        for j in range(len(ornek['tokens'])):\n",
        "            kelime = ornek['tokens'][j]\n",
        "            tur_id = ornek['upos'][j]\n",
        "            kok = ornek['lemmas'][j]\n",
        "            ek_bilgileri_str = ornek['feats'][j]\n",
        "\n",
        "            tur_kodu = POS_NAMES[tur_id]\n",
        "            if tur_kodu in ['PUNCT', 'SYM', 'X']:\n",
        "                continue\n",
        "\n",
        "            if not kok or kok == '_':\n",
        "                kok = kelime.lower()\n",
        "\n",
        "            tur_adi = UD_TO_TR_POS_MAP.get(tur_kodu, tur_kodu.lower())\n",
        "            root_pos_part = f\"{kok}({tur_adi})\"\n",
        "\n",
        "            ek_parcalari = []\n",
        "            if ek_bilgileri_str and ek_bilgileri_str != '_':\n",
        "                feature_list = []\n",
        "                if ek_bilgileri_str.strip().startswith('{'):\n",
        "                    try:\n",
        "                        feat_dict = ast.literal_eval(ek_bilgileri_str)\n",
        "                        feature_list = [f\"{key}={val}\" for key, val in feat_dict.items()]\n",
        "                    except (ValueError, SyntaxError):\n",
        "                        feature_list = ek_bilgileri_str.split('|')\n",
        "                else:\n",
        "                    feature_list = ek_bilgileri_str.split('|')\n",
        "\n",
        "                for ek in feature_list:\n",
        "                    ek_temsili = UD_FEATURE_TO_TR_MAP.get(ek, f\"({ek})\")\n",
        "                    ek_parcalari.append(ek_temsili)\n",
        "\n",
        "            ek_parcalari.sort()\n",
        "\n",
        "            tum_parcalar = [root_pos_part] + ek_parcalari\n",
        "            final_kelime_analizi = \" + \".join(tum_parcalar)\n",
        "\n",
        "            satir = f\"{kelime} -> {final_kelime_analizi}\"\n",
        "            analiz_parcalari.append(satir)\n",
        "\n",
        "        targets.append(\" | \".join(analiz_parcalari))\n",
        "\n",
        "    return {\"input\": inputs, \"target\": targets}"
      ],
      "metadata": {
        "id": "cXkH9ggb-zMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_dataset = dataset.map(\n",
        "    prepare_data_for_training,\n",
        "    batched=True,\n",
        "    remove_columns=dataset['train'].column_names\n",
        ")\n"
      ],
      "metadata": {
        "id": "cKr7OOJr0as_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "1ee870d5b1b141429014742085959ba6",
            "c654572bad2b4f9b9cf65b6cdd24c5d7",
            "4b40bd5676bd4ba0a22cec34ad5c9679",
            "8c7b1a93eba04026a010527cf89aa370",
            "0971e683641f4d4cbbe156d1a5a7112c",
            "b10bec83e5104cc3808ec686bf038e7c",
            "ec025eb5d0a049838e5d2f2264ebad39",
            "bf33b57f73fe46a38da397458e407680",
            "8747f4f144d94b09b56c4c303f79a9db",
            "17abe8306e094867bae918cfaa827e83",
            "a6f9602e412d4e1983d78146e614ffff",
            "b5e923f09ecd4b8c975564024be10548",
            "4477a132313c40069aac38d9a853f675",
            "483b535caa8f464790352721ae921d60",
            "0bc4e49d679e4e26840620b8efc8a100",
            "467ad548a9d744fb8f1f4cb041e3a63f",
            "0d8d38fcebf84ed2a87b0cb47949a363",
            "a82e9f3177bc40fb96b941822a6b23c2",
            "f8e712e4b762425092a02fa95b9b18a1",
            "14b979d069d54b47bb2071985dd0dab2",
            "4f1082a3409e4642bbbcb5823540da94",
            "b3bb9b1af91944a389734cd40f4c3614",
            "d6ec6e73dfb24b85981182f898548ee1",
            "db3c7218934242bdaaf73ae946ae56f5",
            "f9b640f28a87433883ae71aedbf70de1",
            "8939a222fb39424cb7f94f255d7f86aa",
            "89d293e044014ffebd194725761bc74b",
            "9c6c1643c897436295a63ec579572dd9",
            "ad0df1c5cd6a4804ba5ca31ac7366016",
            "5b0dccfa202a4d58bf033d92b8d5d90b",
            "f654f16d2f55463f912d8d14101981d0",
            "0f44ebad6f3743ddba21219026b3b82c",
            "bae501fb64ba4e45bfffc383c9f162bc"
          ]
        },
        "outputId": "425eae47-43cb-46cc-e7dc-67556baaf026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7803 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ee870d5b1b141429014742085959ba6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/979 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5e923f09ecd4b8c975564024be10548"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/979 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6ec6e73dfb24b85981182f898548ee1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    model_inputs = tokenizer(examples['input'], max_length=512, truncation=True)\n",
        "\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples['target'], max_length=512, truncation=True)\n",
        "\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "tokenized_dataset = processed_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=processed_dataset['train'].column_names\n",
        ")"
      ],
      "metadata": {
        "id": "t4E_uln1Bj_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "ce97aa57651746b09d5bc439ada34ce5",
            "a91f0c1a01a6456a8e2b31045863c98a",
            "dc79e5dab2bd4626ac71a78167afc1b3",
            "f5a48a06054f4c86934f1761b924bb24",
            "38bec602dca54401bbf08772b8a2e405",
            "929fb4eb2d574112b43b5933efe4de4a",
            "dad373ad50c34e41a7386a236476bb0a",
            "9ce4e570c60e426193396e4b65cc4f1e",
            "318aa0f0e45448d597de149d386e119b",
            "cecc86c7643c457c98143f0fb6a692a5",
            "a04f20f6bf1f4a39b0ebe982039391af",
            "ed4cc50293d34c8ab02031704ce0454c",
            "3af04d345b2a4e12babdc8a265ef207f",
            "5b02db851188462492a67dc7fcd2b25d",
            "584e4a14beae49b1a77f80251d03f4e4",
            "7ded06a6b4b344e69665765e74ec6a64",
            "00f636524f2e410e8178daaf03b29ccf",
            "ed52ebbd10b445fcbaa415cc136c2d73",
            "953d7f711ee844cd92da126043aba7e0",
            "77851c41501c4d4b91c332b951beceab",
            "34b7649bbf174cb7b350b92998d9f4e3",
            "57b0dbd5b4ac49118232948ed4d776b3",
            "d12a1c9c34a646a3bceb6159a468f5c8",
            "6d41d3a2064742e989a4b1b56dcae78a",
            "b9bde522af484eabb2b37ff324d84d2a",
            "c04f75104a80467db25497491fa84bd8",
            "4f28ea4794894b0db13ec4da34b9bc46",
            "e9f3f25ad2e6403a848514608ac7b662",
            "79093d4047904c918d723dcba9a62323",
            "8ce2652416e0410b86f17b58a55c6492",
            "dee7322acd4b4aad842be135c1e2ccf8",
            "38120974e2654b449d1df0d572156a9c",
            "30335d66d7484f4f8174bae3376d3982"
          ]
        },
        "outputId": "67d24613-6605-4ea7-d725-22bab0abfffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7803 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce97aa57651746b09d5bc439ada34ce5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4006: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/979 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed4cc50293d34c8ab02031704ce0454c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/979 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d12a1c9c34a646a3bceb6159a468f5c8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_metric = evaluate.load(\"rouge\")\n",
        "\n",
        "def normalize_text(text):\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # Label pad tokenlerini -100'den tokenizer.pad_token_id ile değiştir\n",
        "    labels_with_padding = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    # Token ID'leri stringe çevir\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels_with_padding, skip_special_tokens=True)\n",
        "\n",
        "    # Normalize edilmiş metinler\n",
        "    decoded_preds = [normalize_text(p) for p in decoded_preds]\n",
        "    decoded_labels = [normalize_text(l) for l in decoded_labels]\n",
        "\n",
        "    # Rouge hesapla\n",
        "    rouge_result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    rouge_result = {key: value * 100 for key, value in rouge_result.items()} # .mid.fmeasure kaldırıldı\n",
        "\n",
        "    # Kök, POS, affix ve cümle doğrulukları\n",
        "    total_words_evaluated = 0\n",
        "    correct_root_count = 0\n",
        "    correct_pos_count = 0\n",
        "    correct_affix_count = 0\n",
        "    correct_word_exact = 0\n",
        "    correct_full_match_sentence = 0\n",
        "\n",
        "    for pred_text, label_text in zip(decoded_preds, decoded_labels):\n",
        "        pred_lines = [p.strip() for p in pred_text.split('|') if p.strip()]\n",
        "        label_lines = [l.strip() for l in label_text.split('|') if l.strip()]\n",
        "\n",
        "        # Cümledeki kelime sayılarını eşitlemek yerine, ne kadar varsa o kadarını değerlendir\n",
        "        num_words_to_compare = min(len(pred_lines), len(label_lines))\n",
        "        total_words_evaluated += len(label_lines) # Gerçek etiketteki kelime sayısını baz alalım\n",
        "\n",
        "        for i in range(num_words_to_compare):\n",
        "            pred_word = pred_lines[i]\n",
        "            label_word = label_lines[i]\n",
        "\n",
        "            # Kök-POS-affix ayır\n",
        "            # Örnek: \"git(fiil) + -ecek(gelecek z.) + (1.kişi)\"\n",
        "            pred_parts = [p.strip() for p in pred_word.split('->')[-1].split('+')]\n",
        "            label_parts = [l.strip() for l in label_word.split('->')[-1].split('+')]\n",
        "\n",
        "            if len(pred_parts) < 1 or len(label_parts) < 1:\n",
        "                continue # Hatalı formatta üretilmiş kelime analizini atla\n",
        "\n",
        "            pred_root_pos = pred_parts[0]\n",
        "            label_root_pos = label_parts[0]\n",
        "\n",
        "            # Kök ve POS doğruluğu\n",
        "            if pred_root_pos == label_root_pos:\n",
        "                correct_root_count += 1\n",
        "                correct_pos_count += 1\n",
        "\n",
        "            # Affix F1\n",
        "            pred_affix_set = set(pred_parts[1:])\n",
        "            label_affix_set = set(label_parts[1:])\n",
        "\n",
        "            tp = len(pred_affix_set.intersection(label_affix_set))\n",
        "            if not pred_affix_set and not label_affix_set: # İkisinde de ek yoksa, doğru kabul et\n",
        "                 correct_affix_count += 1\n",
        "            elif pred_affix_set or label_affix_set:\n",
        "                precision = tp / len(pred_affix_set) if pred_affix_set else 0\n",
        "                recall = tp / len(label_affix_set) if label_affix_set else 0\n",
        "                if precision + recall > 0:\n",
        "                    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "                    correct_affix_count += f1\n",
        "\n",
        "            # Kelime exact match\n",
        "            if pred_word == label_word:\n",
        "                correct_word_exact += 1\n",
        "\n",
        "        # Cümle exact match\n",
        "        if pred_text == label_text:\n",
        "            correct_full_match_sentence += 1\n",
        "\n",
        "    # Sonuçları hesapla\n",
        "    num_sentences = len(decoded_labels) if decoded_labels else 1\n",
        "    total_words_evaluated = total_words_evaluated if total_words_evaluated > 0 else 1\n",
        "\n",
        "    metrics = {\n",
        "        \"rouge1\": round(rouge_result.get(\"rouge1\", 0), 4),\n",
        "        \"rouge2\": round(rouge_result.get(\"rouge2\", 0), 4),\n",
        "        \"rougeL\": round(rouge_result.get(\"rougeL\", 0), 4),\n",
        "        \"root_pos_acc\": round(correct_root_count / total_words_evaluated, 4),\n",
        "        \"affix_f1\": round(correct_affix_count / total_words_evaluated, 4),\n",
        "        \"word_exact_match\": round(correct_word_exact / total_words_evaluated, 4),\n",
        "        \"sentence_exact_match\": round(correct_full_match_sentence / num_sentences, 4)\n",
        "    }\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "nU9iciImpwyC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "36c3f7a54181429a8d605f48c4601c0d",
            "ce4d20d059c64497951fb9448cd92049",
            "622478a2d0fb4d7487d51b8a1374ce9a",
            "59b1b30aadb84fe9851129d32c0a3386",
            "fe2fd59224d5428d9728b1a5cb69631e",
            "8afd6cdc0b5b42158f038119cf7dd436",
            "abe509b3d46a407896401f3103c7c0ac",
            "9b35fcd3fa1140bb96f8d6454231da9d",
            "f8342525f85249298ec343cbdbfdf21c",
            "c240cc8aa69a43eca83970c31e0dd95c",
            "0badb2c7b90c4a0bb29508e1d19e9d40"
          ]
        },
        "outputId": "d1b437cd-3c2e-43c5-c479-40d0eec7b622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36c3f7a54181429a8d605f48c4601c0d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_kullanici_adi = \"obenadak\"\n",
        "hf_model_adi = \"turkce-morfolojik-analiz-mt0-small\"\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=hf_model_adi,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    predict_with_generate=True,\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    save_total_limit=2,\n",
        "    hub_model_id=f\"{hf_kullanici_adi}/{hf_model_adi}\",\n",
        "    hub_strategy=\"end\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "print(f\"\\n Model '{hf_model_adi}' klasörüne kaydedildi.\")"
      ],
      "metadata": {
        "id": "OJmJ2n2Gxbi8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "3b577672-8a98-4a6a-b3a6-f6577498047c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-179464328.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnebnebo\u001b[0m (\u001b[33mnebnebo-uni\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250813_183357-rjvy0gj0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nebnebo-uni/huggingface/runs/rjvy0gj0' target=\"_blank\">gallant-sun-25</a></strong> to <a href='https://wandb.ai/nebnebo-uni/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nebnebo-uni/huggingface' target=\"_blank\">https://wandb.ai/nebnebo-uni/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nebnebo-uni/huggingface/runs/rjvy0gj0' target=\"_blank\">https://wandb.ai/nebnebo-uni/huggingface/runs/rjvy0gj0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2928' max='2928' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2928/2928 18:30, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Root Pos Acc</th>\n",
              "      <th>Affix F1</th>\n",
              "      <th>Word Exact Match</th>\n",
              "      <th>Sentence Exact Match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>0.266719</td>\n",
              "      <td>17.527400</td>\n",
              "      <td>13.462500</td>\n",
              "      <td>17.281500</td>\n",
              "      <td>0.040100</td>\n",
              "      <td>0.056500</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.341400</td>\n",
              "      <td>0.219509</td>\n",
              "      <td>17.556300</td>\n",
              "      <td>13.700700</td>\n",
              "      <td>17.368600</td>\n",
              "      <td>0.045800</td>\n",
              "      <td>0.061100</td>\n",
              "      <td>0.018500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.207090</td>\n",
              "      <td>17.723700</td>\n",
              "      <td>13.936500</td>\n",
              "      <td>17.524300</td>\n",
              "      <td>0.048200</td>\n",
              "      <td>0.062400</td>\n",
              "      <td>0.019600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Model 'turkce-morfolojik-analiz-mt0-small' klasörüne kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- TEST VERİ SETİ ÜZERİNDE DEĞERLENDİRME BAŞLIYOR ---\")\n",
        "\n",
        "test_sonuclari = trainer.evaluate(\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    metric_key_prefix=\"test\"\n",
        ")\n",
        "\n",
        "print(\"\\n--- TEST VERİ SETİ SONUÇLARI ---\")\n",
        "for key, value in test_sonuclari.items():\n",
        "    print(f\"{key}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "7lwa3laNyFtv",
        "outputId": "d3286f45-430c-408f-838e-fd0d533e394c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TEST VERİ SETİ ÜZERİNDE DEĞERLENDİRME BAŞLIYOR ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [123/123 00:52]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TEST VERİ SETİ SONUÇLARI ---\n",
            "test_loss: 0.2060\n",
            "test_rouge1: 17.7868\n",
            "test_rouge2: 13.9540\n",
            "test_rougeL: 17.6032\n",
            "test_root_pos_acc: 0.0470\n",
            "test_affix_f1: 0.0597\n",
            "test_word_exact_match: 0.0191\n",
            "test_sentence_exact_match: 0.0000\n",
            "test_runtime: 55.4302\n",
            "test_samples_per_second: 17.6620\n",
            "test_steps_per_second: 2.2190\n",
            "epoch: 3.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_path = trainer.state.best_model_checkpoint\n",
        "analiz_cihazi = pipeline(\"text2text-generation\", model=best_model_path, tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "test_cumleleri = [\n",
        "    \"Çok güneşli bir günde yapılacak en iyi şey evde kalmaktır.\",\n",
        "    \"Çay içmeye bayılıyorum.\",\n",
        "    \"Gelecek hafta sonu için planların neler?\",\n",
        "    \"Evden çıkarken ışıkları kapatmayı unutmuşum.\",\n",
        "]\n",
        "\n",
        "def analiz_et_ve_yazdir(cumle):\n",
        "    sonuc = analiz_cihazi(cumle, max_length=512)[0]['generated_text']\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Girdi: {cumle}\")\n",
        "    print(\"Modelin Analizi:\")\n",
        "    print(sonuc)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "for cumle in test_cumleleri:\n",
        "    analiz_et_ve_yazdir(cumle)"
      ],
      "metadata": {
        "id": "gJdnEgxzM5Mm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e4c4503-1031-44ee-9689-12e188000399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Both `max_new_tokens` (=256) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Girdi: Çok güneşli bir günde yapılacak en iyi şey evde kalmaktır.\n",
            "Modelin Analizi:\n",
            "Çok -> Çok(zarf) + (None) | güneşli -> güneş(isim) + (3.kişi) + (tekil) + (yalın) | bir -> bir(belirteç) + (NumType=Card) | günde -> gün(isim) + (3.kişi) + (tekil) + -de(bulunma) | yapılacak -> yapıl(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş) + (olumlu) + (tekil) + -di(geçmiş z.) + -en(sıfat-fiil) | en -> en(zarf) + (None) | iyi -> iyi(sıfat) + (3.kişi) + (tekil) + (yalın) | şey -> şey(isim) + (3.kişi) + (tekil) + (yalın) | evde ->evde(sıfat) + (3.kişi) + (tekil) + (yalın) | kalmaktır -> kal(fiil) + (3.kişi) + (Evident=Fh)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Girdi: Çay içmeye bayılıyorum.\n",
            "Modelin Analizi:\n",
            "Çay -> çay(isim) + (3.kişi) + (tekil) + (yalın) | içmeye -> iç(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş) + (olumlu) + (tekil) + -di(geçmiş z.) | bayılıyorum -> bayılıyor(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş) + (olumlu) + (tekil) + -di(geçmiş z.)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Girdi: Gelecek hafta sonu için planların neler?\n",
            "Modelin Analizi:\n",
            "Gelecek -> gel(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş) + (olumlu) + (tekil) + -ecek(gelecek z.) + -en(sıfat-fiil) | hafta -> hafta(isim) + (3.kişi) + (tekil) + (yalın) | sonu -> son(sıfat) + (3.kişi) + (tekil) + (yalın) | için -> için(edat) + (None) | planların -> plan(isim) + (3.kişi iyelik) + (3.kişi) + (iyelik tekil) + (tekil) + -in(tamlayan) | neler -> ne(zamir) + (3.kişi) + (tekil) + (yalın)\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Girdi: Evden çıkarken ışıkları kapatmayı unutmuşum.\n",
            "Modelin Analizi:\n",
            "Evden -> ev(isim) + (3.kişi) + (tekil) + -den(ayrılma) | çıkarken -> çıkar(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş) + (olumlu) + (tekil) + -di(geçmiş z.) | ışıkları -> ışık(isim) + (3.kişi) + (tekil) + -i(belirtme) | kapatmayı -> kapat(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş) + (olumlu) + (tekil) + -di(geçmiş z.) + -en(sıfat-fiil) | unutmuşum -> unut(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş) + (olumlu) + (tekil) + -di(geçmiş z.)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "login()\n",
        "\n",
        "\n",
        "readme_path = Path(hf_model_adi) / \"README.md\"\n",
        "readme_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "sonuclar_markdown = \"| Metrik | Puan |\\n|---|---|\\n\"\n",
        "for metrik, puan in test_sonuclari.items():\n",
        "    metrik_adi = metrik.replace(\"test_\", \"\").replace(\"_\", \" \").title().replace(\"Acc\", \"Accuracy\").replace(\"F1\", \"F1-Score\").replace(\"Rougel\", \"Rouge-L\")\n",
        "    sonuclar_markdown += f\"| {metrik_adi} | {puan:.4f} |\\n\"\n",
        "\n",
        "# README.md oluştur\n",
        "kart_icerigi = textwrap.dedent(f\"\"\"\n",
        "---\n",
        "license: apache-2.0\n",
        "language:\n",
        "- tr\n",
        "datasets:\n",
        "- universal_dependencies\n",
        "tags:\n",
        "- turkish\n",
        "- morphological-analysis\n",
        "- seq2seq\n",
        "- mt0\n",
        "---\n",
        "\n",
        "# {hf_model_adi}\n",
        "\n",
        "Bu model, Türkçe bir cümlenin morfolojik analizini yapmak için `bigscience/mt0-small` modelinin `universal_dependencies` (`tr_boun` alt kümesi) veri seti üzerinde ince ayarlanmış halidir.\n",
        "## Değerlendirme Sonuçları\n",
        "Model, `universal_dependencies` (`tr_boun`) veri setinin **test** bölümünde aşağıdaki sonuçları elde etmiştir:\n",
        "{sonuclar_markdown}\n",
        "## Modelin Kullanımı\n",
        "```python\n",
        "from transformers import pipeline\n",
        "analiz_cihazi = pipeline(\"text2text-generation\", model=\"{hf_kullanici_adi}/{hf_model_adi}\")\n",
        "cumle = \"Gelecek hafta sonu için planların neler?\"\n",
        "sonuc = analiz_cihazi(cumle, max_length=512)\n",
        "print(sonuc[0]['generated_text'])\"\"\")\n",
        "\n",
        "readme_path.write_text(kart_icerigi, encoding=\"utf-8\")\n"
      ],
      "metadata": {
        "id": "RJi-A2etp2ob",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34,
          "referenced_widgets": [
            "6628161e82fe4f3ba47d96994729ef52",
            "6ad63105a761421893d28481be95ccfa",
            "bf7bd7dd558a435e82d13b83e79b88ce",
            "9c7f48a8a74d4f60a38cdaa1f4c03854",
            "a6bfe4413bda4f67b95a8101dc33d9a4",
            "a9f99e4c03604dfb971bfbf6e1042d2c",
            "6b18c44751c443f0b8fedfa170147901",
            "81edbae6a2704f0aa5ab3cb7831ae7f5",
            "12c6851651484ca284dd10e2c053d535",
            "590e19d813204fca902b2e989202c281",
            "1c89f90d5db54e998019e1ed05ffc388",
            "5b8d426074e34785a195af83b3e12372",
            "9ae6f4ca31a54b32b89e6c949a211e14",
            "af42df268a624679bdf7275ebbea7503",
            "981e1f4af1be47e9be71531afebd9430",
            "05b917475224481da4cd3b6be0ae64de",
            "03c86a5253de4712a63053782a8cd549",
            "8dc6da4ec8d744e5a320e4deefb4b4ee",
            "308e02f4c6c147e4a5276da1e9b0fb13",
            "0ac28561d4524d8fb6ac9bc74aae263d"
          ]
        },
        "outputId": "9e6dd313-ec06-4677-eac4-c671f2e6af38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6628161e82fe4f3ba47d96994729ef52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1135"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(commit_message=\"Eğitim ve test tamamlandı, model ve README yüklendi.\")"
      ],
      "metadata": {
        "id": "_C-xapOJ5KyW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325,
          "referenced_widgets": [
            "0032174464fe477b8d44d4273cd85c48",
            "08b978f09efc4f55a1c4e4033095d360",
            "c9daf34b931b47af9acc3454b64b914f",
            "4913880c0e6341609af0eb2794f175a2",
            "f497fa79df344f10a5699609b82ea17a",
            "d271d19a700c4b8397b658ed71552ef0",
            "16c08183083041418e90c3c47aa5255d",
            "3d5b4bcf66844a0b9f5d95354b2d59fa",
            "994acaf4f91b4d8f844861d974b2da3c",
            "908593f913c6427183cd200d05818a2f",
            "858fb5680f8847b6b471db8100884290",
            "4f44d97e1630473ca2e2ae79e0459228",
            "3d732773c4f5493c8cbf6770e0cee388",
            "10c7daff7b0d4789a70efb20f16a155b",
            "5d205e6c183546bd859b9c9730509fd5",
            "f2ba3011cbfe473091a1c7c8e82e54e9",
            "6fde66b1665b475eae7b4342ee9d1c05",
            "f9ac9d42ea7e4ff3b859a697e049cd1c",
            "7fccd0f8da9647228d258081c2cf8ce8",
            "dcdbe2417c5b4f23ab7e1d7f5b10f5a2",
            "e91469ca12a745b6bfbd6b9af4ab2b73",
            "d0ce9c5616ef46c492b9cf75c798a17e",
            "3083cd58095d4c6d9c863fb80b134a7d",
            "e9438eabe4844e8988ef577adb2813de",
            "d7eab9cd58c9462496e41dcb8e5b0925",
            "9667ff3e42cb4496bb607a0e0bd0dd49",
            "efad193060974335b9fa9241de578260",
            "09e472de06a34f21816008eba559ab4a",
            "ee8d4f51f03b498b90014d346dc88793",
            "3ef8229d5a124c1cb2f976d3eced4566",
            "81b1675d95d641c99e8ac66241a99198",
            "6dc56ddf96944f5b8ff26bd237c073fe",
            "17073d4a4d22449abbed3359b3aa1df6",
            "1bb391085f2547229fa5fc937bde0a13",
            "e9179f32cfa74f5d96e936c4d68ba602",
            "e10001e9b8424983a6802905669b42c6",
            "ab5759972d194880afb8c6333fb35e25",
            "c00de084cfae4281aef42edc571aa1a9",
            "b109f82cd64745ca8fa01848588658ae",
            "09f091dfde2d40b9b9eaa393e60913ca",
            "3931d1f0ccbc459cbf751a88d56b3719",
            "29e1a013368345b0875d5409db7d1d34",
            "9659d05143434c24b8109004a0409c1c",
            "44fbebb53bb144038a291e5c17d11d78",
            "70cd5f87cdf644ae97d0161deb184b0e",
            "7fdb7d081ae34cb19f56d4f879d918df",
            "ba0102605e4e43fab251724577f911d8",
            "34913506651147a0891ec6045857ab2a",
            "41fdb00d0ff74bd6b2ec49d9d993ad3b",
            "93c5a7efa26946b488025e5e78b3ab26",
            "ea5ffe15106440b4815862bdadb75c59",
            "f154ab81dc5842c991aa77d33429cb4f",
            "cd665b1912944e4787456b11d09c1005",
            "d836cd1ffff743b3a367371aaea815d9",
            "1ae31c6fa9ee441384a64e6271a0d41b",
            "fc3b3dedd0864295aa873259cce7acb1",
            "989e94aa2d69408f8a8d17174a992999",
            "ec86264dba3d4b8e81c094a4209d57d4",
            "70588700d62f4f02a50464c2b1695eaf",
            "1f7afc2469b14a708dda1edc074c30bd",
            "a7587906e4da48169ba60814d1e63b41",
            "aa1886eafed54405a105d75ba3984f35",
            "c9ce3e8569e04fcb9ef7c2f4bbef6c94",
            "25ee491f313d4c09a222417a41af79b2",
            "c09de84aefae45d9930c326fa228bffd",
            "88edaac7039041c78d9ca3d777c1e919",
            "9109c4418353496c9ec817edbb0adec0",
            "b589d3bc60274ebaafb09e89a424bd50",
            "55b87ead417a40bb8261a649a0e98fc7",
            "ea579ff69b1b4695ba843ef5ac74c29b",
            "e5a3418536b44130a5b1ef42086d946b",
            "bcb5b644feda48bc853634bc2b1562e3",
            "c44acc4c82814738b0bea67171a09372",
            "1fc00835824141e69527814425b5f67f",
            "7e87a4a1b8214fe3983ea56cbf6a5996",
            "375c248f41b34a949e374f592449604f",
            "65aa175d496440e68ddd7d27c87c0c3e",
            "cc7177a372db40d8b2102c548c5acd41",
            "7f0c8f5eb3da427aaa5e02909f9d4a8e",
            "b96d04ff5b8e470aa41f990435176551",
            "dc3d896f7b07442db7d60c94e4c63362",
            "6dfe70fd9d8f45f88149b9c98a411a6e",
            "aa0d0f720fc94f5592d553ad79833276",
            "5e3ed7c3c11c4e24a69d67111b77f8e2",
            "810c4019557940998ee89fbb034e9fc9",
            "e59e46b012d44391a131cb9d3225227c",
            "9a989f3782844a5893f9b016a92d9536",
            "2a417f24acb64f679f1f117a229089e9"
          ]
        },
        "outputId": "85ed6b5b-5e90-4282-dedd-43ec944e8bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0032174464fe477b8d44d4273cd85c48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New Data Upload                         : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f44d97e1630473ca2e2ae79e0459228"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...lojik-analiz-mt0-small/spiece.model: 100%|##########| 4.31MB / 4.31MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3083cd58095d4c6d9c863fb80b134a7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...jik-analiz-mt0-small/tokenizer.json:  99%|#########9| 16.2MB / 16.3MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bb391085f2547229fa5fc937bde0a13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...-analiz-mt0-small/model.safetensors:   0%|          | 19.7kB / 1.20GB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70cd5f87cdf644ae97d0161deb184b0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...vents.1755110024.0f1b137612e1.432.0:  14%|#3        | 1.13kB / 8.26kB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc3b3dedd0864295aa873259cce7acb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...vents.1755111358.0f1b137612e1.432.1:  14%|#3        |   101B /   741B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9109c4418353496c9ec817edbb0adec0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...-analiz-mt0-small/training_args.bin:  14%|#3        |   759B / 5.56kB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc7177a372db40d8b2102c548c5acd41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/obenadak/turkce-morfolojik-analiz-mt0-small/commit/f9c52554adff6d0264ea78e27179552ce428f307', commit_message='Eğitim ve test tamamlandı, model ve README yüklendi.', commit_description='', oid='f9c52554adff6d0264ea78e27179552ce428f307', pr_url=None, repo_url=RepoUrl('https://huggingface.co/obenadak/turkce-morfolojik-analiz-mt0-small', endpoint='https://huggingface.co', repo_type='model', repo_id='obenadak/turkce-morfolojik-analiz-mt0-small'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}