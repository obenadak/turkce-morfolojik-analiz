{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets==3.6.0\n",
        "!pip install transformers[sentencepiece] accelerate evaluate rouge_score conllu -q\n",
        "\n",
        "from pathlib import Path\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import login, ModelCard, ModelCardData\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    pipeline,\n",
        ")\n",
        "import os, re, textwrap, evaluate\n",
        "import numpy as np\n",
        "import ast"
      ],
      "metadata": {
        "id": "RqQPdWxo-Obv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbbce60c-a736-4626-d3e4-e71a91e7bd1f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==3.6.0\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.6.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: datasets\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed datasets-3.6.0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"universal_dependencies\", \"tr_boun\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "UgkBHbtl-QOv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397,
          "referenced_widgets": [
            "4a53f80266e845e0877b62f7338c4c9f",
            "13936674842c4c77b411367ec3e7db89",
            "b7bb1f8733004c498cf06b81c2fedee3",
            "1a519fb333184ce383ff08f09f199aa3",
            "5164adddd6484591ad88b0bd0fab1767",
            "7b6a472d68584098b77275a231935b46",
            "cf592ffe1a284d13a3b054c86b113058",
            "9e7ca0e0d04b49efb11ccd3e63a70a64",
            "fa1d1b372ac24039aa815ee177c048ae",
            "327ecfea65de48e4a58561348e1108c4",
            "98e442af364e42c39108b27f5e8e7a33",
            "3e316d0a015145d687150b9dce2df48a",
            "30768d68b3d244bebd824bc49c54c075",
            "ced3ec7782ee4859b01e2d0f9644ad2b",
            "ff43b2e24fd848c7a5d3e3ce676ab934",
            "302fa81004fb44a6ad215350a9f34171",
            "e4047ec53adc47c99467a52d08e64170",
            "cbd262e9ea034eeea73936505d3fb060",
            "ebe805d50f70466aab94190fcf6c8b60",
            "ad2672e45d004be7a1da5ce147615ce2",
            "77a435f32cfa4d84984b7a68849fab77",
            "8af5286dcd284171aecd9d606b6457a9",
            "9e3296b56b5c47eb9805c52e26cacfab",
            "5cfbdee530b8481ba33404e1b9313fa9",
            "92afa97a8c4543dc924e9e1caad95854",
            "ef0589832fb14779b7530c3cf756ad3e",
            "bb8cb55ee9144962bbe8ba3d53da5783",
            "dce396568dbb4664a3e12f8ea7be3df4",
            "37caed08da2945f3b1a1888ff30a5cd9",
            "2174c7860ed64ed89eae7482ac4adb3b",
            "3c6545333b4f4309b207e9f9344dd2de",
            "3ea886a4466345288501d3df18415e6c",
            "dfe179cc22d5450e94b15294d1c859f7",
            "2c8575050463407fadc27205d5a864af",
            "8b7b158d0b6a4c1d979d4476906f0402",
            "3a8e96ba80e74480986ec87ca16b3c15",
            "f424a39a6ea748c0ae45c712557b3d75",
            "3343fb04e69445cda4f9a96284f7d6e8",
            "7cddcdbc77e84039885ca0d8e1200caf",
            "2b494ec69a5844b6ae4baad38e71fe3d",
            "cfeb5fb003614d85892723a32f46b375",
            "95359b2f60dc49deb1a968580a6d7643",
            "7c992ef2936f4ed1bf20ba9110299100",
            "f6bade835bbf47e9aef456015f4d74e6",
            "9fd677b900ae498c9a59552ac44197f4",
            "2819b26b4b434be98b617d0c57abd08f",
            "c717d1b8a0c94facada4e17025dc524d",
            "47e6eb4702fd48c2a00429bdb6ab5f98",
            "418118ffd795491080094e079be21667",
            "787c26510bec4bda9dae515e724ee8e7",
            "53f08508cd464ade91e34518e857de06",
            "d52e222f38c3442584f08ee9fe5d55a4",
            "eb3cda5ddf154182905fe453af93e6b7",
            "bf795f388e22439ab6b737037e557a6d",
            "d577eae697194076a1b1c7eccb4e82e8",
            "159a418cadb4476aa99e42285040c2f7",
            "f6aca7b7e807417fb6b96797de7d192f",
            "4eeb68addd144f9eaba0f6353c46fa3b",
            "cf092225e6164aa18094925949886144",
            "4f837016c73d4e29b820cdde8fbda5bc",
            "03902c14d9f44bb2b28d3b65af64ee13",
            "f5d21acb0adc4df095959b77c45e20cc",
            "2967d5dcfbae4d9a88b6466f1c1e922c",
            "8aa9ea5f0edc43508d98bc34caf84f65",
            "dc7dcb17a1ca4652bd1ef515e239d67e",
            "6194b5499cda405eaf32d4df23501d73",
            "668424a39f89490686399ef232364dc7",
            "f9cc2e72855c468080ef1856eefb2971",
            "5a7ec2ed2f904196b39610fe56197b39",
            "f9f747ff2ed0405bba6fadd54baab521",
            "60a7e9df59094d09ab4c86e555b81011",
            "7aa1fbd832de4a6f8b68a7127a4e51e8",
            "153c345de3a04dc2bdd86e69bd4b270e",
            "3031833b6acd43f794b01cc1d573ff77",
            "cdb7649e876f43b9af4376deca006543",
            "b6ccb0e4b8304ff38f62fe5eba7fe735",
            "03b72375da8b46508e5098046a26f60e",
            "836204af333d4602b09d52f5c5664164",
            "c501f75235a24570ab4379c665f06b22",
            "b0fb92bbaaff464693b975b59edfa4ca",
            "19ed84cf0ae948eea1b3744e25c4984c",
            "18995b09e5584cb68549bb89379eff2d",
            "26f103713f4e4eec8270afb8b677f34d",
            "ab03b20c6d1f43889e43775d815f16fa",
            "22415cac32f848be9a0abf86c20a6fbc",
            "41340b0a1925466d8b5e5cd9138fba1c",
            "98b57c160b0b4deba1e83276208c74d6",
            "3908dc6f99b84ffc91e824782ce111b7"
          ]
        },
        "outputId": "8654a219-1470-46c5-e710-d6272997a0da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a53f80266e845e0877b62f7338c4c9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "universal_dependencies.py: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e316d0a015145d687150b9dce2df48a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/7.82M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e3296b56b5c47eb9805c52e26cacfab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/962k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c8575050463407fadc27205d5a864af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/963k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fd677b900ae498c9a59552ac44197f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/7803 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "159a418cadb4476aa99e42285040c2f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/979 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "668424a39f89490686399ef232364dc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/979 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "836204af333d4602b09d52f5c5664164"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "Janu-PaWbmuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "256935ce-4b92-4b05-fbc1-1803bd240dac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
            "        num_rows: 7803\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
            "        num_rows: 979\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
            "        num_rows: 979\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = len(dataset['train'])\n",
        "validation_size = len(dataset['validation'])\n",
        "test_size = len(dataset['test'])\n",
        "\n",
        "print(f\"Eğitim veriseti boyutu: {train_size} cümle\")\n",
        "print(f\"Doğrulama veriseti boyutu: {validation_size} cümle\")\n",
        "print(f\"Test veriseti boyutu: {test_size} cümle\")"
      ],
      "metadata": {
        "id": "pLoPsWavbsYA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc25b5b-f4f6-4890-c027-2e968b15806d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eğitim veriseti boyutu: 7803 cümle\n",
            "Doğrulama veriseti boyutu: 979 cümle\n",
            "Test veriseti boyutu: 979 cümle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_names = dataset['train'].features['upos'].feature.names\n",
        "\n",
        "print(\"Kelime Türü Numaraları ve Karşılıkları:\")\n",
        "for i, name in enumerate(pos_names):\n",
        "    print(f\"Sayı: {i:<5} -> Metin: {name}\")"
      ],
      "metadata": {
        "id": "yTG2cUejCt9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbcca193-be18-4ccb-9a12-ae67e2b5794d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kelime Türü Numaraları ve Karşılıkları:\n",
            "Sayı: 0     -> Metin: NOUN\n",
            "Sayı: 1     -> Metin: PUNCT\n",
            "Sayı: 2     -> Metin: ADP\n",
            "Sayı: 3     -> Metin: NUM\n",
            "Sayı: 4     -> Metin: SYM\n",
            "Sayı: 5     -> Metin: SCONJ\n",
            "Sayı: 6     -> Metin: ADJ\n",
            "Sayı: 7     -> Metin: PART\n",
            "Sayı: 8     -> Metin: DET\n",
            "Sayı: 9     -> Metin: CCONJ\n",
            "Sayı: 10    -> Metin: PROPN\n",
            "Sayı: 11    -> Metin: PRON\n",
            "Sayı: 12    -> Metin: X\n",
            "Sayı: 13    -> Metin: _\n",
            "Sayı: 14    -> Metin: ADV\n",
            "Sayı: 15    -> Metin: INTJ\n",
            "Sayı: 16    -> Metin: VERB\n",
            "Sayı: 17    -> Metin: AUX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ilk_ornek = dataset['train'][333]\n",
        "print(\"--- CÜMLENİN ORİJİNALİ ---\")\n",
        "print(ilk_ornek['text'])\n",
        "print(\"\\n--- CÜMLENİN PARÇALARI ---\")\n",
        "\n",
        "for i in range(len(ilk_ornek['tokens'])):\n",
        "    kelime = ilk_ornek['tokens'][i]\n",
        "    kok = ilk_ornek['lemmas'][i]\n",
        "    tur_id = ilk_ornek['upos'][i]\n",
        "    tur_metni = pos_names[tur_id]\n",
        "    ekler = ilk_ornek['feats'][i]\n",
        "\n",
        "    print(f\"Kelime: {kelime:<15} | Kök: {kok:<15} | Tür: {tur_metni:<10} | Ek Bilgileri: {ekler}\")"
      ],
      "metadata": {
        "id": "LZu5IUQoBdkr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "391cd5b7-955d-4b65-8461-fdf63e41a5d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- CÜMLENİN ORİJİNALİ ---\n",
            "Ben titriyor, için için ağlıyor ve hiçbir şey yapamamanın ezikliğini yaşıyordum.\n",
            "\n",
            "--- CÜMLENİN PARÇALARI ---\n",
            "Kelime: Ben             | Kök: ben             | Tür: PRON       | Ek Bilgileri: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1'}\n",
            "Kelime: titriyor        | Kök: titre           | Tür: VERB       | Ek Bilgileri: {'Aspect': 'Prog', 'Number': 'Sing', 'Person': '3', 'Polarity': 'Pos', 'Tense': 'Pres'}\n",
            "Kelime: ,               | Kök: ,               | Tür: PUNCT      | Ek Bilgileri: None\n",
            "Kelime: için            | Kök: için            | Tür: ADV        | Ek Bilgileri: None\n",
            "Kelime: için            | Kök: için            | Tür: ADP        | Ek Bilgileri: None\n",
            "Kelime: ağlıyor         | Kök: ağla            | Tür: VERB       | Ek Bilgileri: {'Aspect': 'Prog', 'Number': 'Sing', 'Person': '3', 'Polarity': 'Pos', 'Tense': 'Pres'}\n",
            "Kelime: ve              | Kök: ve              | Tür: CCONJ      | Ek Bilgileri: None\n",
            "Kelime: hiçbir          | Kök: hiçbir          | Tür: DET        | Ek Bilgileri: None\n",
            "Kelime: şey             | Kök: şey             | Tür: NOUN       | Ek Bilgileri: {'Case': 'Nom', 'Number': 'Sing', 'Person': '3'}\n",
            "Kelime: yapamamanın     | Kök: yap             | Tür: VERB       | Ek Bilgileri: {'Case': 'Gen', 'Number': 'Sing', 'Person': '3', 'Polarity': 'Neg'}\n",
            "Kelime: ezikliğini      | Kök: ezik            | Tür: NOUN       | Ek Bilgileri: {'Case': 'Acc', 'Number': 'Sing', 'Number[psor]': 'Sing', 'Person': '3', 'Person[psor]': '3'}\n",
            "Kelime: yaşıyordum      | Kök: yaşa            | Tür: VERB       | Ek Bilgileri: {'Aspect': 'Prog', 'Evident': 'Fh', 'Number': 'Sing', 'Person': '1', 'Polarity': 'Pos', 'Tense': 'Past'}\n",
            "Kelime: .               | Kök: .               | Tür: PUNCT      | Ek Bilgileri: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bigscience/mt0-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "HbDUaCTHKT4X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "fd0f3f185efa4fe484db85d1c73bd04f",
            "27f3cdea5a464c108b14df4f677a1fe1",
            "7c6342ab007f42c4b9c6f118ded92bfe",
            "6cfec91b2cb042debd371f78b4375a94",
            "3026062560fa4766b71355d4e570dae3",
            "fcba469e638b4276aa24c08a1deceba0",
            "b43fbb077bc043ed9dd9a6c716b43642",
            "d3e3e3633af448f88fc150de58c17724",
            "5c5afdf2c49a497ab15eda81263f6078",
            "50c1c3fc4b4e4fffa1265a70690bf1e0",
            "0ac67a4fe4054d23bc69a535dea9e280",
            "bb9ac7366a1f4cd785a3fa3f795e13ad",
            "8b778a12eb59469fba90e3694a699b05",
            "0c3d24de7cb74e28bc86708e6a7f82fe",
            "0159a60090fb4aba8e154af4ea8d9580",
            "1abb1cc0b2dd4fe2907b0e97b93f1bbf",
            "451749a9ee274e079fa321f4e2632507",
            "0163501857774d758a8388bc2877b775",
            "9ab3df58362c4f73b2ea1cd8667c258d",
            "9be6b43bca3244b6bcd44613021af534",
            "761ecaf6126c4f789a6d8e8b7f1171a3",
            "f124b9b02bc8442199a4ff2ce69b84be",
            "8d8650e29a324c8eb831ba242425ead6",
            "3e16bdc32a9841d28692da4b053b5f13",
            "5912dbd152d14f16a700e37824e259ae",
            "0da9701c18fc4ea0bdbf4bce1c8d4b47",
            "1773192117fa4bc388624c5c8a54d212",
            "0a1f163e148c4b96be387b0d77634d33",
            "eab36241487545d29044c0ba56bec98e",
            "d2cd961efcde47168c9d0d7d2742bd5e",
            "72e44db06f62416d9bf6a52ed70ebbfe",
            "106b274f10f5433cb4b8779eb5f72693",
            "592f881122644ecc8dbe19420e382121",
            "b91e22f9d97d4f2fbd7d3b646bef562c",
            "ee3eb1d1bcc14d588e67b5b9fe545912",
            "1a0aac23376342ad94ebd372fa26aa8f",
            "46e812cc74e54f508707da3c5c29d11b",
            "5ed27c530fd84907a36bdc9c0be6b90e",
            "c2b5366deca143368f6fc12c425d2dcb",
            "c088c7392af047aeac03ae04538c34e1",
            "48947ba2bdcd4eca875c2f7468bd348f",
            "329124c0bd194f00be364f502a95a42a",
            "507ec502dd9c4d62ba004f383cb84e17",
            "b0b54cfce3964d2097ecf9caf74e3b9d",
            "d30a2e9b596d407d80c0c32190b2d409",
            "c2a36f1f6d694cf98063a2f1c79db9a3",
            "12c496a807c74c63b74ea21085bfe232",
            "6490e47ff8654238ae8935b8d350b125",
            "26047831e9214244a7193a37acfd15cb",
            "a48fa1204ef04979938c013336989b16",
            "5595152751aa4c6ea75435e6fd03799a",
            "04b56959761b4a4b8b0febf9d9b844f4",
            "0316b549cd1041a8b7a32d4999eefc02",
            "fdfa17d5cf044581a73079d07ebe2e64",
            "69e24cf6589c4af6841ea7d6003e79a7",
            "dcfa0cef5e404c7c9c154a5ce673a2c2",
            "aba33649410d471f9cc69cee6a15db06",
            "300e5fe15f21408c860169f87154f7d2",
            "59e6920e25c14cdf9b2b683d3575a719",
            "baedf039de10468096efec2ec5e61514",
            "6caa3b4665ee4fd4b99c913d03cfe5f9",
            "29fd703785024daf97da0088c8b61c37",
            "24be745d093d49c4b9c63a340099bcbe",
            "866ebc6ce9d84bee94c4fc9e338e5c97",
            "9e4d7f45f9da4279b7ac8894b1da7f0f",
            "4d0cb51658e74afcba49ffec9996b93c"
          ]
        },
        "outputId": "c8c22872-564a-448a-dee0-52c64dd14a51"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/430 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd0f3f185efa4fe484db85d1c73bd04f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb9ac7366a1f4cd785a3fa3f795e13ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d8650e29a324c8eb831ba242425ead6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b91e22f9d97d4f2fbd7d3b646bef562c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/773 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d30a2e9b596d407d80c0c32190b2d409"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcfa0cef5e404c7c9c154a5ce673a2c2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UD_TO_TR_POS_MAP = {\n",
        "    \"NOUN\": \"isim\", \"VERB\": \"fiil\", \"ADJ\": \"sıfat\", \"ADV\": \"zarf\",\n",
        "    \"PRON\": \"zamir\", \"PROPN\": \"özel isim\", \"NUM\": \"sayı\", \"ADP\": \"edat\",\n",
        "    \"CCONJ\": \"bağlaç\", \"AUX\": \"yardımcı fiil\", \"DET\": \"belirteç\",\n",
        "    \"PART\": \"partikül\", \"SCONJ\": \"alt-bağlaç\", \"INTJ\": \"ünlem\",\n",
        "}\n",
        "\n",
        "\n",
        "UD_FEATURE_TO_TR_MAP = {\n",
        "    \"Case=Acc\": \"-i(belirtme)\", \"Case=Dat\": \"-e(yönelme)\", \"Case=Loc\": \"-de(bulunma)\",\n",
        "    \"Case=Abl\": \"-den(ayrılma)\", \"Case=Gen\": \"-in(tamlayan)\", \"Case=Ins\": \"-le(vasıta)\",\n",
        "    \"Case=Nom\": \"(yalın)\",\n",
        "    \"Number=Sing\": \"(tekil)\", \"Number=Plur\": \"-ler(çoğul)\",\n",
        "    \"Number[psor]=Sing\": \"(iyelik tekil)\", \"Number[psor]=Plur\": \"(iyelik çoğul)\",\n",
        "    \"Person=1\": \"(1.kişi)\", \"Person=2\": \"(2.kişi)\", \"Person=3\": \"(3.kişi)\",\n",
        "    \"Person[psor]=1\": \"(1.kişi iyelik)\", \"Person[psor]=2\": \"(2.kişi iyelik)\", \"Person[psor]=3\": \"(3.kişi iyelik)\",\n",
        "    \"Tense=Pres\": \"-(i)yor(şimdiki z.)\", \"Tense=Past\": \"-di(geçmiş z.)\", \"Tense=Fut\": \"-ecek(gelecek z.)\",\n",
        "    \"Tense=Pqp\": \"-mişti(öğ. geç. hik.)\",\n",
        "    \"Aspect=Perf\": \"(belirli geçmiş)\", \"Aspect=Prog\": \"-mekte(sürmekte)\",\n",
        "    \"Aspect=Hab\": \"-er(geniş z.)\",\n",
        "    \"Polarity=Neg\": \"-me(olumsuzluk)\", \"Polarity=Pos\": \"(olumlu)\",\n",
        "    \"VerbForm=Vnoun\": \"-mek(isim-fiil)\", \"VerbForm=Part\": \"-en(sıfat-fiil)\", \"VerbForm=Conv\": \"-erek(zarf-fiil)\",\n",
        "    \"Mood=Imp\": \"(emir)\", \"Mood=Opt\": \"-e(istek)\", \"Mood=Cnd\": \"-se(şart)\",\n",
        "    \"Mood=Pot\": \"-ebil(yeterlilik)\", \"Mood=Gen\": \"(genel kip)\",\n",
        "    \"Voice=Pass\": \"-il(edilgen)\", \"Voice=Rcp\": \"-iş(işteş)\", \"Voice=Cau\": \"-dir(ettirgen)\",\n",
        "    \"PronType=Prs\": \"(kişi zamiri)\"\n",
        "}\n",
        "\n",
        "POS_NAMES = dataset['train'].features['upos'].feature.names\n",
        "\n",
        "def prepare_data_for_training(dataset_batch):\n",
        "    inputs, targets = [], []\n",
        "    num_rows = len(dataset_batch[list(dataset_batch.keys())[0]])\n",
        "\n",
        "    for i in range(num_rows):\n",
        "        ornek = {key: dataset_batch[key][i] for key in dataset_batch}\n",
        "        inputs.append(ornek['text'])\n",
        "\n",
        "        analiz_parcalari = []\n",
        "        for j in range(len(ornek['tokens'])):\n",
        "            kelime = ornek['tokens'][j]\n",
        "            tur_id = ornek['upos'][j]\n",
        "            kok = ornek['lemmas'][j]\n",
        "            ek_bilgileri_str = ornek['feats'][j]\n",
        "\n",
        "            tur_kodu = POS_NAMES[tur_id]\n",
        "            if tur_kodu in ['PUNCT', 'SYM', 'X']:\n",
        "                continue\n",
        "\n",
        "            if not kok or kok == '_':\n",
        "                kok = kelime.lower()\n",
        "\n",
        "            tur_adi = UD_TO_TR_POS_MAP.get(tur_kodu, tur_kodu.lower())\n",
        "            root_pos_part = f\"{kok}({tur_adi})\"\n",
        "\n",
        "            ek_parcalari = []\n",
        "            if ek_bilgileri_str and ek_bilgileri_str != '_':\n",
        "                feature_list = []\n",
        "                if ek_bilgileri_str.strip().startswith('{'):\n",
        "                    try:\n",
        "                        feat_dict = ast.literal_eval(ek_bilgileri_str)\n",
        "                        feature_list = [f\"{key}={val}\" for key, val in feat_dict.items()]\n",
        "                    except (ValueError, SyntaxError):\n",
        "                        feature_list = ek_bilgileri_str.split('|')\n",
        "                else:\n",
        "                    feature_list = ek_bilgileri_str.split('|')\n",
        "\n",
        "                for ek in feature_list:\n",
        "                    ek_temsili = UD_FEATURE_TO_TR_MAP.get(ek, f\"({ek})\")\n",
        "                    ek_parcalari.append(ek_temsili)\n",
        "\n",
        "            ek_parcalari.sort()\n",
        "\n",
        "            tum_parcalar = [root_pos_part] + ek_parcalari\n",
        "            final_kelime_analizi = \" + \".join(tum_parcalar)\n",
        "\n",
        "            satir = f\"{kelime} -> {final_kelime_analizi}\"\n",
        "            analiz_parcalari.append(satir)\n",
        "\n",
        "        targets.append(\" | \".join(analiz_parcalari))\n",
        "\n",
        "    return {\"input\": inputs, \"target\": targets}"
      ],
      "metadata": {
        "id": "cXkH9ggb-zMj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_dataset = dataset.map(\n",
        "    prepare_data_for_training,\n",
        "    batched=True,\n",
        "    remove_columns=dataset['train'].column_names\n",
        ")\n"
      ],
      "metadata": {
        "id": "cKr7OOJr0as_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "25ad9adffb814473851e72c8f21b353b",
            "4522006acd7d439bb965109a0ba451d2",
            "f9ca6b6cc4f3429c8ea5ea5cdb72b4bd",
            "a92c4a56ac2746a38bd0897c9d949427",
            "283e5406d8a54be8ba7e0b1c59ba1688",
            "e490ebbefbdc41bcb4a74f74c6fc6b38",
            "d427e74e93c849bfbeb1cec79581bf1c",
            "1eb55f75ef314f629e76280a41340275",
            "48a3762e56f74468a43aaa1d0194fb0a",
            "2ab1055fc3ed4660a94d977e4acca3f7",
            "5fcd05a328204e92be88d12bb60a736d",
            "8470791ccb66459cb95a2eb1a7f21069",
            "9f002e9681924746a9dbe0e6c1b828d9",
            "73086cb5ba5346d699d14ab6e76618ec",
            "b9db3c6835dd485bbc0e53fa140fba74",
            "bfdc4d7e8fed4910b76d9cb070730e42",
            "41a9e591b5054b9a9802e285248eceb8",
            "4d9b9ede13c249e18e5b1699680c33dd",
            "35b40796b6d84043874a6e0dc039e529",
            "5ce42d7db5d942b8872b2a117f43c502",
            "1adde655e039477dab0e99542ff20a54",
            "a1c42faf5ef546e98897af8484c26df5",
            "c456bc2c2022418988e3cf5c49708f8b",
            "a754b53e5b6d474f969e139cc560960c",
            "30641ff23e4a41a0b7a2c2983d87f691",
            "7026364458ef45aca0730abea094eb91",
            "d019941f5d8d48e1a33783672eeaf1de",
            "9a515caa3c0048b8b02c7532ff2a8580",
            "a25638c982a04a989747de4592ed96a5",
            "d7b03b59808746b0a0d98ce1b445c4e4",
            "e618d953d90b45ce89a47184d73eb56e",
            "eb235921264d46c08eac8cf46d48a065",
            "553bd6601c13469daac50ba9d6cc4e26"
          ]
        },
        "outputId": "50d38842-5150-45c7-b74f-e963139e141f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7803 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25ad9adffb814473851e72c8f21b353b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/979 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8470791ccb66459cb95a2eb1a7f21069"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/979 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c456bc2c2022418988e3cf5c49708f8b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    model_inputs = tokenizer(examples['input'], max_length=512, truncation=True)\n",
        "\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples['target'], max_length=512, truncation=True)\n",
        "\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "tokenized_dataset = processed_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=processed_dataset['train'].column_names\n",
        ")"
      ],
      "metadata": {
        "id": "t4E_uln1Bj_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "3ccbd5a0ed0f44d4aa7a4269cdfed4ce",
            "7adf4629c7c7423484e1eb43c3081c15",
            "fa013ac1530147739fb77e9d6ecc778b",
            "24873580056b41668527dd609b5a0bfc",
            "e47fab79f16f4a39b6b60310c0682a04",
            "ddffcfb27be54fcab83096f1ceccd72a",
            "33cdf66ad7ab4edcbc562e911948c7d3",
            "64c1969b33654d4b89e5118d032ce1ef",
            "76d866ebddff4dce9e76d7bce6d90c16",
            "311e4c9a9add4621b6b56eb05b2fe270",
            "09a92b9efb804645bef1411fdda60ef8",
            "cfbd5d4ace3c44c089088cbeeecb1b04",
            "f802e30a44904f2e9fb563cccd3222c7",
            "18d491fee069460d9766ba9729774d76",
            "cae6ac5f60ae49eda1c5a01c5776635a",
            "4b9f989a08834388931509dba2cd0e71",
            "86085cfcc8a34bf29e4b9c34ae66e17a",
            "14a778b0b71545f395e0aaf3e0ad8bd1",
            "b5471a72a5b446b6934b07909b01d340",
            "781db896b5294930a5b35028f715924a",
            "c97869917f2f4e7fac68dc82cd52ed17",
            "46d1a13dec8d4b1c9066e30488e624b7",
            "25c3e14c75e04cc995d0315986d8b3be",
            "8195d8c5841a4189b16e240ac06307b1",
            "b0aa8096a53d4560a8a4eeaea28611bf",
            "8d5d4e956105448bb88d2f37e33967a0",
            "d59fb839043e4b6db82593472859a572",
            "d34b6d57f35f42b59b74d63ec23b77d6",
            "1b07b70ba6bb4014873c28542de69905",
            "c6a7d3351bfa4c61b7209d1f7797ea30",
            "f2336bb660be4c748ca5262535c1ce07",
            "6fbc4760e12b4dfa9cd51d1ca0ae7150",
            "961cf124995643d2ad7b814a2a06ce3e"
          ]
        },
        "outputId": "3637f123-5089-4e49-be68-1620603393f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7803 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ccbd5a0ed0f44d4aa7a4269cdfed4ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4006: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/979 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfbd5d4ace3c44c089088cbeeecb1b04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/979 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25c3e14c75e04cc995d0315986d8b3be"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_metric = evaluate.load(\"rouge\")\n",
        "\n",
        "def normalize_text(text):\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # Label pad tokenlerini -100'den tokenizer.pad_token_id ile değiştir\n",
        "    labels_with_padding = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    # Token ID'leri stringe çevir\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels_with_padding, skip_special_tokens=True)\n",
        "\n",
        "    # Normalize edilmiş metinler\n",
        "    decoded_preds = [normalize_text(p) for p in decoded_preds]\n",
        "    decoded_labels = [normalize_text(l) for l in decoded_labels]\n",
        "\n",
        "    # Rouge hesapla\n",
        "    rouge_result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=False)\n",
        "    rouge_result = {key: value * 100 for key, value in rouge_result.items()} # .mid.fmeasure kaldırıldı\n",
        "\n",
        "    # Kök, POS, affix ve cümle doğrulukları\n",
        "    total_words_evaluated = 0\n",
        "    correct_root_count = 0\n",
        "    correct_pos_count = 0\n",
        "    correct_affix_count = 0\n",
        "    correct_word_exact = 0\n",
        "    correct_full_match_sentence = 0\n",
        "\n",
        "    for pred_text, label_text in zip(decoded_preds, decoded_labels):\n",
        "        pred_lines = [p.strip() for p in pred_text.split('|') if p.strip()]\n",
        "        label_lines = [l.strip() for l in label_text.split('|') if l.strip()]\n",
        "\n",
        "        # Cümledeki kelime sayılarını eşitlemek yerine, ne kadar varsa o kadarını değerlendir\n",
        "        num_words_to_compare = min(len(pred_lines), len(label_lines))\n",
        "        total_words_evaluated += len(label_lines) # Gerçek etiketteki kelime sayısını baz alalım\n",
        "\n",
        "        for i in range(num_words_to_compare):\n",
        "            pred_word = pred_lines[i]\n",
        "            label_word = label_lines[i]\n",
        "\n",
        "            # Kök-POS-affix ayır\n",
        "            # Örnek: \"git(fiil) + -ecek(gelecek z.) + (1.kişi)\"\n",
        "            pred_parts = [p.strip() for p in pred_word.split('->')[-1].split('+')]\n",
        "            label_parts = [l.strip() for l in label_word.split('->')[-1].split('+')]\n",
        "\n",
        "            if len(pred_parts) < 1 or len(label_parts) < 1:\n",
        "                continue # Hatalı formatta üretilmiş kelime analizini atla\n",
        "\n",
        "            pred_root_pos = pred_parts[0]\n",
        "            label_root_pos = label_parts[0]\n",
        "\n",
        "            # Kök ve POS doğruluğu\n",
        "            if pred_root_pos == label_root_pos:\n",
        "                correct_root_count += 1\n",
        "                correct_pos_count += 1\n",
        "\n",
        "            # Affix F1\n",
        "            pred_affix_set = set(pred_parts[1:])\n",
        "            label_affix_set = set(label_parts[1:])\n",
        "\n",
        "            tp = len(pred_affix_set.intersection(label_affix_set))\n",
        "            if not pred_affix_set and not label_affix_set: # İkisinde de ek yoksa, doğru kabul et\n",
        "                 correct_affix_count += 1\n",
        "            elif pred_affix_set or label_affix_set:\n",
        "                precision = tp / len(pred_affix_set) if pred_affix_set else 0\n",
        "                recall = tp / len(label_affix_set) if label_affix_set else 0\n",
        "                if precision + recall > 0:\n",
        "                    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "                    correct_affix_count += f1\n",
        "\n",
        "            # Kelime exact match\n",
        "            if pred_word == label_word:\n",
        "                correct_word_exact += 1\n",
        "\n",
        "        # Cümle exact match\n",
        "        if pred_text == label_text:\n",
        "            correct_full_match_sentence += 1\n",
        "\n",
        "    # Sonuçları hesapla\n",
        "    num_sentences = len(decoded_labels) if decoded_labels else 1\n",
        "    total_words_evaluated = total_words_evaluated if total_words_evaluated > 0 else 1\n",
        "\n",
        "    metrics = {\n",
        "        \"rouge1\": round(rouge_result.get(\"rouge1\", 0), 4),\n",
        "        \"rouge2\": round(rouge_result.get(\"rouge2\", 0), 4),\n",
        "        \"rougeL\": round(rouge_result.get(\"rougeL\", 0), 4),\n",
        "        \"root_pos_acc\": round(correct_root_count / total_words_evaluated, 4),\n",
        "        \"affix_f1\": round(correct_affix_count / total_words_evaluated, 4),\n",
        "        \"word_exact_match\": round(correct_word_exact / total_words_evaluated, 4),\n",
        "        \"sentence_exact_match\": round(correct_full_match_sentence / num_sentences, 4)\n",
        "    }\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "nU9iciImpwyC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ac9e1e8e9ac34001b09045002d393c1d",
            "7122a962f1ee42458d42b83f5d9ecfe7",
            "e4c6d46b22d14771bdd8e82b7fbe9b09",
            "d821e007a3d645b8aca2903056feeb7d",
            "97fc7e1954844bd08bd7c0e48bb01667",
            "5b137dcf92ab43f68721149953243b06",
            "489a35ec3e68476ab6604868c4d38f0f",
            "029b80a8f3eb46b5bda1c3604ce70b38",
            "9ef6dc1be0fe4f05b29d1dd9434a3914",
            "8023056bec434524b3ce503135bed224",
            "d4036b89b7d74a73a8e403bb3a54b175"
          ]
        },
        "outputId": "3fb0953a-3672-4cfc-dde2-146a26fd1a87"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac9e1e8e9ac34001b09045002d393c1d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_kullanici_adi = \"obenadak\"\n",
        "hf_model_adi = \"turkce-morfolojik-analiz-mt0-small\"\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=hf_model_adi,\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    predict_with_generate=True,\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    save_total_limit=2,\n",
        "    hub_model_id=f\"{hf_kullanici_adi}/{hf_model_adi}\",\n",
        "    hub_strategy=\"end\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "print(f\"\\n Model '{hf_model_adi}' klasörüne kaydedildi.\")"
      ],
      "metadata": {
        "id": "OJmJ2n2Gxbi8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "e5cd93a3-9322-46bc-f7a6-a1ca022402af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3391337965.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnebnebo\u001b[0m (\u001b[33mnebnebo-uni\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250814_120909-d0v52u6x</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nebnebo-uni/huggingface/runs/d0v52u6x' target=\"_blank\">glowing-puddle-26</a></strong> to <a href='https://wandb.ai/nebnebo-uni/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nebnebo-uni/huggingface' target=\"_blank\">https://wandb.ai/nebnebo-uni/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nebnebo-uni/huggingface/runs/d0v52u6x' target=\"_blank\">https://wandb.ai/nebnebo-uni/huggingface/runs/d0v52u6x</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4880' max='4880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4880/4880 30:38, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Root Pos Acc</th>\n",
              "      <th>Affix F1</th>\n",
              "      <th>Word Exact Match</th>\n",
              "      <th>Sentence Exact Match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.823500</td>\n",
              "      <td>0.258775</td>\n",
              "      <td>17.568600</td>\n",
              "      <td>13.559600</td>\n",
              "      <td>17.365300</td>\n",
              "      <td>0.041400</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.016300</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.323600</td>\n",
              "      <td>0.203823</td>\n",
              "      <td>17.661800</td>\n",
              "      <td>13.881100</td>\n",
              "      <td>17.472200</td>\n",
              "      <td>0.047800</td>\n",
              "      <td>0.062000</td>\n",
              "      <td>0.018900</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.266100</td>\n",
              "      <td>0.176962</td>\n",
              "      <td>17.735100</td>\n",
              "      <td>14.187500</td>\n",
              "      <td>17.543000</td>\n",
              "      <td>0.055200</td>\n",
              "      <td>0.063600</td>\n",
              "      <td>0.022600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.238900</td>\n",
              "      <td>0.165271</td>\n",
              "      <td>17.841000</td>\n",
              "      <td>14.339900</td>\n",
              "      <td>17.659100</td>\n",
              "      <td>0.056900</td>\n",
              "      <td>0.063700</td>\n",
              "      <td>0.024100</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.227100</td>\n",
              "      <td>0.160540</td>\n",
              "      <td>17.820700</td>\n",
              "      <td>14.299800</td>\n",
              "      <td>17.628900</td>\n",
              "      <td>0.056400</td>\n",
              "      <td>0.064300</td>\n",
              "      <td>0.024300</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Model 'turkce-morfolojik-analiz-mt0-small' klasörüne kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sonuclari = trainer.evaluate(\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    metric_key_prefix=\"test\"\n",
        ")\n",
        "\n",
        "print(\"\\n--- TEST VERİ SETİ SONUÇLARI ---\")\n",
        "for key, value in test_sonuclari.items():\n",
        "    print(f\"{key}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "7lwa3laNyFtv",
        "outputId": "c06eafdd-e720-4922-ad83-469c9235a8ba"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [123/123 00:51]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TEST VERİ SETİ SONUÇLARI ---\n",
            "test_loss: 0.1581\n",
            "test_rouge1: 17.9301\n",
            "test_rouge2: 14.2752\n",
            "test_rougeL: 17.7252\n",
            "test_root_pos_acc: 0.0550\n",
            "test_affix_f1: 0.0620\n",
            "test_word_exact_match: 0.0232\n",
            "test_sentence_exact_match: 0.0000\n",
            "test_runtime: 53.7059\n",
            "test_samples_per_second: 18.2290\n",
            "test_steps_per_second: 2.2900\n",
            "epoch: 5.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_path = trainer.state.best_model_checkpoint\n",
        "analiz_cihazi = pipeline(\"text2text-generation\", model=best_model_path, tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "test_cumleleri = [\n",
        "    \"Çok güneşli bir günde yapılacak en iyi şey evde kalmaktır.\",\n",
        "    \"Çay içmeye bayılıyorum.\",\n",
        "    \"Gelecek hafta sonu için planların neler?\",\n",
        "    \"Evden çıkarken ışıkları kapatmayı unutmuşum.\",\n",
        "]\n",
        "\n",
        "def analiz_et_ve_yazdir(cumle):\n",
        "    sonuc = analiz_cihazi(cumle, max_length=512)[0]['generated_text']\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Girdi: {cumle}\")\n",
        "    print(\"Modelin Analizi:\")\n",
        "    print(sonuc)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "for cumle in test_cumleleri:\n",
        "    analiz_et_ve_yazdir(cumle)"
      ],
      "metadata": {
        "id": "gJdnEgxzM5Mm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ecb891-d836-482c-beb5-16928e2a684a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Both `max_new_tokens` (=256) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Girdi: Çok güneşli bir günde yapılacak en iyi şey evde kalmaktır.\n",
            "Modelin Analizi:\n",
            "Çok -> Çok(zarf) + (None) | güneşli -> güneş(isim) + (3.kişi) + (tekil) + (yalın) | bir -> bir(belirteç) + (NumType=Card) | günde -> gün(isim) + (3.kişi) + (tekil) + -de(bulunma) | yapılacak -> yap(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş) + (olumlu) + (tekil) + -di(geçmiş z.) + -en(sıfat-fiil) | en -> en(zarf) + (None) | iyi -> iyi(sıfat) + (None) | şey -> şey(isim) + (3.kişi) + (tekil) + (yalın) | evde ->evde(zarf) + (3.kişi) + (tekil) + -de(bulunma) | kalmaktır -> kal(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Girdi: Çay içmeye bayılıyorum.\n",
            "Modelin Analizi:\n",
            "Çay -> çay(isim) + (3.kişi) + (tekil) + (yalın) | içmeye -> iç(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş) + (olumlu) + (tekil) + -di(geçmiş z.) | bayılıyorum -> bayılıyor(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş) + (olumlu) + (tekil) + -di(geçmiş z.)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Girdi: Gelecek hafta sonu için planların neler?\n",
            "Modelin Analizi:\n",
            "Gelecek -> gel(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş) + (olumlu) + (tekil) + -di(geçmiş z.) | hafta -> hafta(isim) + (3.kişi) + (tekil) + (yalın) | sonu -> son(sıfat) + (3.kişi) + (tekil) + (yalın) | için -> için(edat) + (None) | planların -> plan(isim) + (3.kişi iyelik) + (3.kişi) + (iyelik tekil) + (tekil) + -in(tamlayan) | neler -> ne(zamir) + (3.kişi) + (tekil) + -(i)yor(şimdiki z.) + -ler(çoğul)\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Girdi: Evden çıkarken ışıkları kapatmayı unutmuşum.\n",
            "Modelin Analizi:\n",
            "Evden -> ev(isim) + (3.kişi) + (tekil) + -den(ayrılma) | çıkarken -> çıkar(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş) + (olumlu) + (tekil) + -di(geçmiş z.) | ışıkları -> ışık(isim) + (3.kişi) + -i(belirtme) + -ler(çoğul) | kapatmayı -> kapat(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş) + (olumlu) + (tekil) + -di(geçmiş z.) + -en(sıfat-fiil) | unutmuşum -> unut(fiil) + (3.kişi) + (Evident=Fh) + (belirli geçmiş) + (olumlu) + (tekil) + -di(geçmiş z.)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import upload_folder\n",
        "\n",
        "login()\n",
        "\n",
        "trainer.save_model(hf_model_adi)\n",
        "print(f\"Model ve tokenizer '{hf_model_adi}' klasörüne kaydedildi.\")\n",
        "\n",
        "\n",
        "\n",
        "hyperparameters_markdown = f\"\"\"\n",
        "- **Base Model:** `{model_name}`\n",
        "- **Epochs:** `{training_args.num_train_epochs}`\n",
        "- **Training Batch Size:** `{training_args.per_device_train_batch_size}`\n",
        "- **Evaluation Batch Size:** `{training_args.per_device_eval_batch_size}`\n",
        "- **Optimizer:** AdamW (varsayılan)\n",
        "- **Learning Rate:** `{training_args.learning_rate}`\n",
        "- **Dataset:** `universal_dependencies` (tr_boun)\n",
        "\"\"\"\n",
        "\n",
        "validation_sonuclari = {}\n",
        "for log in reversed(trainer.state.log_history):\n",
        "    if 'eval_loss' in log:\n",
        "        validation_sonuclari = {f\"validation_{k.replace('eval_', '')}\": v for k, v in log.items() if k not in ['step', 'epoch']}\n",
        "        break\n",
        "\n",
        "print(\"\\n--- Final Validation Sonuçları ---\")\n",
        "for key, value in validation_sonuclari.items():\n",
        "    print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "def create_results_table(results_dict):\n",
        "    header_map = {\n",
        "        'loss': 'Loss', 'rouge1': 'Rouge1', 'rouge2': 'Rouge2', 'rougeL': 'RougeL',\n",
        "        'root_pos_acc': 'Root & POS Accuracy', 'affix_f1': 'Affix F1-Score',\n",
        "        'word_exact_match': 'Word Exact Match', 'sentence_exact_match': 'Sentence Exact Match',\n",
        "        'runtime': 'Runtime (s)',\n",
        "        'samples_per_second': 'Samples / Second',\n",
        "        'steps_per_second': 'Steps / Second'\n",
        "    }\n",
        "    markdown = \"| Metrik | Puan |\\n|---|---|\\n\"\n",
        "    for key, value in results_dict.items():\n",
        "        if '_' in key:\n",
        "            clean_key = key.split('_', 1)[1]\n",
        "        else:\n",
        "            clean_key = key\n",
        "\n",
        "        metric_name = header_map.get(clean_key, clean_key.replace(\"_\", \" \").title())\n",
        "\n",
        "        if isinstance(value, (int, float)):\n",
        "            markdown += f\"| {metric_name} | {value:.4f} |\\n\"\n",
        "\n",
        "    return markdown\n",
        "\n",
        "validation_sonuclari_markdown = create_results_table(validation_sonuclari)\n",
        "test_sonuclari_markdown = create_results_table(test_sonuclari)\n",
        "\n",
        "# README.md oluştur\n",
        "readme_path = Path(hf_model_adi) / \"README.md\"\n",
        "readme_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "kart_icerigi = textwrap.dedent(f\"\"\"\n",
        "---\n",
        "license: apache-2.0\n",
        "language:\n",
        "- tr\n",
        "datasets:\n",
        "- universal_dependencies\n",
        "tags:\n",
        "- turkish\n",
        "- morphological-analysis\n",
        "- seq2seq\n",
        "- mt0\n",
        "---\n",
        "\n",
        "# Türkçe Morfolojik Analiz Modeli: {hf_model_adi}\n",
        "\n",
        "Bu model, Türkçe cümlelerin morfolojik analizini yapmak üzere `{model_name}` modelinin `universal_dependencies` (`tr_boun` alt kümesi) veri seti üzerinde ince ayarlanmasıyla (fine-tuning) eğitilmiştir.\n",
        "\n",
        "Model, bir cümledeki her kelimeyi alıp kökünü, kelime türünü (Part-of-Speech) ve aldığı ekleri tahmin eder. Çıktı formatı aşağıdaki gibidir:\n",
        "\n",
        "`Kelime -> kök(tür) + ek_1 + ek_2 ...`\n",
        "\n",
        "## Eğitim Hiperparametreleri\n",
        "{hyperparameters_markdown}\n",
        "\n",
        "---\n",
        "\n",
        "## Modelin Kullanımı\n",
        "\n",
        "```python\n",
        "from transformers import pipeline\n",
        "\n",
        "analiz_cihazi = pipeline(\"text2text-generation\", model=\"{hf_kullanici_adi}/{hf_model_adi}\")\n",
        "cumle = \"Gelecek hafta sonu için planların neler?\"\n",
        "sonuc = analiz_cihazi(cumle, max_length=512)\n",
        "print(sonuc[0]['generated_text'])\n",
        "\n",
        "# Beklenen Çıktı (Örnek):\n",
        "# Gelecek -> gel(fiil) + -ecek(gelecek z.) | hafta -> hafta(isim) + (yalın) | sonu -> son(isim) + (3.kişi iyelik) + (yalın) | için -> için(edat) | planların -> plan(isim) + -ler(çoğul) + (2.kişi iyelik) + (yalın) | neler -> ne(zamir) + -ler(çoğul)\n",
        "# Değerlendirme Sonuçları (Evaluation Results)\n",
        "\n",
        "Model, **tr_boun** veri setinin doğrulama (validation) ve test kümelerinde aşağıdaki sonuçları elde etmiştir.\n",
        "\n",
        "## Final Doğrulama (Validation) Sonuçları\n",
        "{validation_sonuclari_markdown}\n",
        "\n",
        "## Test Seti Sonuçları\n",
        "{test_sonuclari_markdown}\n",
        "\n",
        "---\n",
        "## Veri Hazırlığı (Data Preprocessing)\n",
        "\n",
        "Girdi olarak cümlenin ham metni (**text**) kullanılır.\n",
        "Hedef (**target**) ise, **universal_dependencies** veri setindeki **lemmas**, **upos** ve **feats** sütunları kullanılarak yapılandırılmış bir dizedir.\n",
        "Noktalama işaretleri analizden çıkarılmıştır.\n",
        "\"\"\")\n",
        "\n",
        "readme_path.write_text(kart_icerigi, encoding=\"utf-8\")\n",
        "\n",
        "upload_folder(\n",
        "    folder_path=hf_model_adi,\n",
        "    repo_id=f\"{hf_kullanici_adi}/{hf_model_adi}\",\n",
        "    commit_message=\"Epoch sayısı 5'e çıkarıldı, ROUGE use_stemmer=False olarak güncellendi.\"\n",
        ")"
      ],
      "metadata": {
        "id": "RJi-A2etp2ob",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713,
          "referenced_widgets": [
            "84ff2fc91f3c448988fd6c89e12424fd",
            "303026a8499a41f79edb4b346c19bc53",
            "5b4da7f889e5411d82c37ce1851243b6",
            "bfc9da127e164c30b89e91eb66f59a88",
            "de969e9613844e56bc1407961833642c",
            "bd4b9962f01e42f39dd0491a77c30efc",
            "472cca0b6d324892aa7ee2b143512fb2",
            "09b7ced04b9b44f781c6ef2dd5c02c07",
            "3bff6b69bd084fcb91d0254fcd6dbc72",
            "7b73ad79622d473789ee41ef4c360872",
            "81ed51c7f16b4aaa80421ffb59287274",
            "08ac453944f54d2b886b3d024f771c99",
            "1c1f40835bd2416ab2c0c326ad3eaf52",
            "28dba6f1b543481e90a846c531ed48fe",
            "98ef2782722e4cbab3bc43d8d12b6378",
            "3a62e4c1196242f283a60c56ddeeba79",
            "bedbf241cda34a928cf74a5ac58575b0",
            "f51e811cd07f459bb13314a23fea30c3",
            "5851519503e74732a47d7e7163be690c",
            "51e2a5ec45f0435f8713f6f11f51984c",
            "b0c9a9dc350c453db9042e3a9670e341",
            "ea28ffb0b1a242de9f804d449c799050",
            "036261abe87a485cac4d1097ba4757ff",
            "35ca915b73014260b53c602ba2675af9",
            "c4d3ab22fffc472d9eb5afa1f6eb14de",
            "5b0d9afe53f944378f9f9fac738cb5ce",
            "8549acf904e440809792cd79ddd88853",
            "40de44628226402ebbc076776cc99c5e",
            "73b0e39b28ff42d59ae04b5a56f710b6",
            "bce1499612fe4968a90bd36612f55091",
            "106452aed1e4410e95769913fc8b73a5",
            "7e400829928b474bb7f8e4db06779fc3",
            "c1875985b8744d2a93c8ed5077ad9793",
            "a0f61aacb9414038bd92abde2514afd5",
            "f026033b9af442d98343ef3949c4efc7",
            "470b9181de5b44c6bde7f419f6adc935",
            "15da6c6d130848899141fc3e119339fe",
            "fd6a9cb9729744d19f32ee9b9f98c210",
            "eee6adcf75ec454386defe6abafa779f",
            "c3f9d97dea1b4468a4bfdad99f303b39",
            "785c94946d41414c9addc683eae8fc82",
            "55586d075e5847e49b0362ccf897d99a",
            "d5217c4794cd4d5ca73b911458fc5af1",
            "feb4494f7c3a4161befa96b6fd38a7c2",
            "c941aec6cbe24c91bc2f6495bb15fb5c",
            "c144df205bab46a093529323b794d3fe",
            "390118eca3e7490aa1e8186ca817edd1",
            "2c43121def964b08be3ff56ff6f5d2e7",
            "1aba7432d15a4655bb5996ca012edc35",
            "bfb70960d72540ab899d24082d5ea785",
            "beacd9123c39446cae26820574d331bc",
            "cc3facfb75cc4856af9185b56ba57bbd",
            "ec3a1f7fe613402fb1f33527585aa6ec",
            "7d69a5ff3ba34a1ab29c84e50dbca154",
            "4d4e781ef4cd44c59183b8dc0d1468a3",
            "13dc1725c87f4c1aa67f7e8c96a4a09f",
            "eee79b5bd05f4d8a9e9417681185764f",
            "4453fa35495a4cc3972fb38b930eefd1",
            "1c7d8a80054b4b4bb448a7fe63bdd3bc",
            "0a385434796e46d1b4467d592753b009",
            "cf3246ddf92040028fb846aa72b20ce2",
            "b8baae66054f43d28a80d0a2b7c342bb",
            "b7456d65c1384f3aa6e2ab5f8d7e43ae",
            "55476bb89fd340d0a7b14dbcdd7cc12e",
            "7e9d7783bdc8496999041f324b02a2dc",
            "451754999694475d97b36efedf4d7519",
            "c28990ba4954404989d8d0c270b8da4f",
            "9e06e48e7d4a45dba1e11b7c74dc0805",
            "ba6d725a18ec4c16a048ccf72af04f61",
            "b0606873858543a0abec804f8aeb7f13",
            "8539b85e9efa4983ae04eb4373493fc6",
            "86c39de048d949cd9cd9346a897873ce",
            "04037f6c02524846b512702b740562f4",
            "8d2dbe85cf00411e8db12b7ea9c78282",
            "a8ca6017a5b246a684f741b09133dc38",
            "f88dd6d7eb9f4cb1a739cae7a0a86395",
            "363715fbacf540d3a2a8cc2c2ac774c6",
            "e145e64e901d41379a6da587ca8d02c5",
            "5811dfecf6414dc68ad41f6dd3dab599",
            "d853b72d19974329a72084e5acb70dfb",
            "51efd22ec549456594c129ad04a94402",
            "92e050a11c11405a92f8e3b5b91ef1bb",
            "ebae50f9b2f44a748ebdec7cb43dd0f4",
            "87365747d5094603a978d36af31ad794",
            "d8b1ef401ff74e768db437f50c2055ca",
            "e4e6e9c8a60b408a9f06486760a688c6",
            "f55ea783eb5c42a2b14666337de3d3a1",
            "e4abfe941ed2487e96723141f34f52cd",
            "7d91e37e463a4130a4855696df453230",
            "de25d63c738949dc91be2f9060e69568",
            "d81bc5f2c7e1470f9dd904b2db93da2e",
            "23d86f173e444441ae29a8bd1aa1e5a5",
            "716ea2324504469b916592410005c993",
            "2072c34673fe4bf59d248673eb3d96c1",
            "42f0667d2fd943ccbc1dede2819ca19b",
            "7469d02a1baf4c559106056a0ecb28d0",
            "b96ac6aea95a44b982e84ad44d6df5d6",
            "e9158b3b8f0d4eb8832e7df27e3148da",
            "9d22367cdcc14acda014436a715bdc9a",
            "93c94ecf22f1478186ab1577a024ee78",
            "f97d8370c6c44bd8865b6de394a11583",
            "18fb38e374224fffaefc4b13ec44e537",
            "6c7199806b5b4b2597a43989fe8fccba",
            "5b0bb1e49cdd40688ac3092598da74ef",
            "046b4d4268524bba82e00392f043de78",
            "efce19d33eba4fc2ad6d170965cebca1",
            "603b5b2ad3314d9882876a0d661556a2",
            "9830b01ef4de4d97a17d2644dc4efaa8",
            "3f23e458719e464da5070ff83e131005",
            "e186e64b10264168b2a487317ab915c6",
            "782398d83d854cdb96aa926c9c864d5b",
            "71a8981a9f9942339127e70397788eaa",
            "557bb30c15794f8a99c5919fa115acc7",
            "07e041a984ae4cd096fe8839e5fb8de3",
            "ff9650bb65f74c56b2a6f927b216cb6b",
            "ae1b650b455348f585b786df64e580fe",
            "4234271d5f8a47d58f554c28c2268628",
            "92644d7073cc49009a60c35848616d01",
            "ea37be70e4fe4f20bb14a0a61c6795cc",
            "7165c272f62d40979d27b019ac65bfe3",
            "1565af554bbd41f0b2a09dcb136c327d",
            "7aa748ec2e734739a2e15ab7515bccec",
            "8a0b59acf48748d89cddb395c02889cc",
            "3fa4f1bd983c495cb37e5c6d1e04b7a4",
            "4c1fdb9d11d74655a67daac493965be5",
            "1049edecaf764786aeb4b35e7bcae325",
            "750891e22c144802a1f7ae4cac087eb3",
            "c28ee431004a48b8ba1d54415b25bcbc",
            "3315156e14a9448f96255f47a04bba01",
            "c08801cdb3354d36a29382efaed830c8",
            "00dd9862345b4fbdbb8ce02814bc1686",
            "584dba7617f34b87a31501b7d5142ab3",
            "bb2709ebf49744b093c642bcd073077f",
            "fa1af9705aa64d80b9d8f7b3d2a3be51",
            "a8ab42fc38b6401fb7884d3438ca33e2",
            "49bbb46e73e4423e974cb254dc0bf6a1",
            "17016c3eff7048ab8596c7ad6aed5c20",
            "4da7a547e928443ea2dde2302313a39b",
            "dd04de5506cd4e4ab66f8bd30b4dfcf9",
            "295c24a688bc48efb6f1989b9379553a",
            "383c4a7b2e83466798a5372d329c3f8b",
            "127753ef4d5948ef959805724747c979",
            "dbea9079a1c3445a9a26a3184820d309",
            "f46e88a837c4448fbd33ec73d8c75c23",
            "f4d5f61770be4a94884189c9c2e136ae",
            "65b57ff51e254886aaaaf312dde9cccf",
            "4c501bf2debb49b383323d5d27a70266",
            "17e699fd118d4c20b9bf6f10aeb0c742",
            "7dbb03ed6b9a4d26be644ce1899e9000",
            "055304dfa03b4b48a9d91c25aecb033c",
            "4a0dfbd05c864e979257ce8b48788655",
            "eb0f26895f3841408d338d3b6690cb0b"
          ]
        },
        "outputId": "9dbf83b1-8b19-48ba-b85c-536f3f898ea8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84ff2fc91f3c448988fd6c89e12424fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ve tokenizer 'turkce-morfolojik-analiz-mt0-small' klasörüne kaydedildi.\n",
            "\n",
            "--- Final Validation Sonuçları ---\n",
            "validation_loss: 0.1605\n",
            "validation_rouge1: 17.8207\n",
            "validation_rouge2: 14.2998\n",
            "validation_rougeL: 17.6289\n",
            "validation_root_pos_acc: 0.0564\n",
            "validation_affix_f1: 0.0643\n",
            "validation_word_exact_match: 0.0243\n",
            "validation_sentence_exact_match: 0.0000\n",
            "validation_runtime: 54.1345\n",
            "validation_samples_per_second: 18.0850\n",
            "validation_steps_per_second: 2.2720\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f51e811cd07f459bb13314a23fea30c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New Data Upload                         : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73b0e39b28ff42d59ae04b5a56f710b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...small/checkpoint-4880/rng_state.pth:  78%|#######7  | 11.0kB / 14.2kB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3f9d97dea1b4468a4bfdad99f303b39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...-small/checkpoint-4880/spiece.model:  95%|#########5| 4.11MB / 4.31MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "beacd9123c39446cae26820574d331bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...lojik-analiz-mt0-small/spiece.model:  95%|#########5| 4.11MB / 4.31MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8baae66054f43d28a80d0a2b7c342bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...mall/checkpoint-3904/tokenizer.json:   3%|2         |  433kB / 16.3MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04037f6c02524846b512702b740562f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...jik-analiz-mt0-small/tokenizer.json:   3%|2         |  433kB / 16.3MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87365747d5094603a978d36af31ad794"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...-small/checkpoint-3904/spiece.model: 100%|##########| 4.31MB / 4.31MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42f0667d2fd943ccbc1dede2819ca19b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...mall/checkpoint-4880/tokenizer.json:   3%|2         |  433kB / 16.3MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efce19d33eba4fc2ad6d170965cebca1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...small/checkpoint-3904/rng_state.pth:  78%|#######7  | 11.0kB / 14.2kB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4234271d5f8a47d58f554c28c2268628"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...l/checkpoint-4880/model.safetensors:   0%|          | 19.7kB / 1.20GB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c28ee431004a48b8ba1d54415b25bcbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...-analiz-mt0-small/model.safetensors:   0%|          | 19.7kB / 1.20GB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd04de5506cd4e4ab66f8bd30b4dfcf9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/obenadak/turkce-morfolojik-analiz-mt0-small/commit/4eac45ccc49913b2e7b7a4de425b287de203f9be', commit_message=\"Epoch sayısı 5'e çıkarıldı, ROUGE use_stemmer=False olarak güncellendi.\", commit_description='', oid='4eac45ccc49913b2e7b7a4de425b287de203f9be', pr_url=None, repo_url=RepoUrl('https://huggingface.co/obenadak/turkce-morfolojik-analiz-mt0-small', endpoint='https://huggingface.co', repo_type='model', repo_id='obenadak/turkce-morfolojik-analiz-mt0-small'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trainer.push_to_hub(commit_mesaji = \"Epoch sayısı 5'e çıkarıldı, ROUGE use_stemmer=False olarak güncellendi.\")"
      ],
      "metadata": {
        "id": "_C-xapOJ5KyW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}